âš™ï¸ APÃŠNDICE A â€” BACKEND (continuaÃ§Ã£o)

ObservaÃ§Ã£o: assumo que vocÃª jÃ¡ colou os arquivos A1â†’A6 que enviei antes (index, utils, middlewares, schemas).
Os trechos abaixo nÃ£o substituem aqueles; adicionam.

ðŸ§© A7. server/routes/index.ts â€” Registro central de rotas
import type { Express } from "express";
import { registerHealthRoutes } from "./health";
import { registerChatRoutes } from "./chat";
import { registerChatStream } from "./chat-stream";
import { registerKbRoutes } from "./kb";
import { registerCurationRoutes } from "./curation";
import { registerAgentRoutes } from "./agents";
import { registerPolicyRoutes } from "./policy";
import { registerPolicyAudit } from "./policy-audit";
import { registerMetricsRoutes } from "./metrics";

export function registerRoutes(app: Express) {
  registerHealthRoutes(app);
  registerChatRoutes(app);
  registerChatStream(app);
  registerKbRoutes(app);
  registerCurationRoutes(app);
  registerAgentRoutes(app);
  registerPolicyRoutes(app);
  registerPolicyAudit(app);
  registerMetricsRoutes(app);
}

ðŸ§© A8. server/routes/health.ts
import type { Express, Request, Response } from "express";
import { ok } from "../utils/http";

export function registerHealthRoutes(app: Express) {
  app.get("/health", (_req: Request, res: Response) => ok(res, { status: "ok" }));
  app.get("/version", (_req: Request, res: Response) => ok(res, { version: process.env.APP_VERSION || "dev" }));
}

ðŸ§© A9. server/llm/priority-orchestrator.ts â€” Orquestrador (run + stream)
// Simplificado: escolhe entre modelo local, GPU workers gratuitos, provedores free e por fim OpenAI.
// VocÃª pode plugar aqui sua polÃ­tica de confianÃ§a e custo.

type RunPayload = {
  sessionId: string;
  input: string;
  files?: { id: string; name: string; mime: string }[];
  options?: { temperature?: number; top_p?: number };
};

async function localLLMGenerate(prompt: string, opts: any) {
  // chame seu servidor local (PyTorch) ou pipeline Python via HTTP
  const r = await fetch(process.env.LOCAL_MODEL_URL || "http://localhost:7001/generate", {
    method: "POST",
    headers: { "Content-Type":"application/json" },
    body: JSON.stringify({ prompt, ...opts })
  });
  if (!r.ok) throw new Error(`local-llm-fail:${r.status}`);
  return r.json();
}

async function freeGPUWorkerGenerate(prompt: string, opts: any) {
  // round-robin/circuit-breaker nos workers gratuitos (Colab/Kaggle/Modal)
  const workers = (process.env.GPU_WORKERS || "").split(",").map(s => s.trim()).filter(Boolean);
  for (const w of workers) {
    try {
      const r = await fetch(`${w}/generate`, { method: "POST", headers: { "Content-Type":"application/json" }, body: JSON.stringify({ prompt, ...opts })});
      if (r.ok) return r.json();
    } catch {}
  }
  throw new Error("gpu-workers-unavailable");
}

async function freeProviderGenerate(prompt: string, opts: any) {
  // OpenRouter/Groq/Gemini/HF gratuitos: implemente conforme suas chaves
  const r = await fetch(process.env.FREE_PROVIDER_URL || "http://localhost:7001/free", {
    method: "POST",
    headers: { "Content-Type":"application/json" },
    body: JSON.stringify({ prompt, ...opts })
  });
  if (!r.ok) throw new Error("free-provider-fail");
  return r.json();
}

async function openaiFallback(prompt: string, opts: any) {
  const r = await fetch(process.env.OPENAI_PROXY_URL || "http://localhost:7001/openai", {
    method: "POST",
    headers: { "Content-Type":"application/json" },
    body: JSON.stringify({ prompt, ...opts })
  });
  if (!r.ok) throw new Error("openai-fail");
  return r.json();
}

export const generateWithPriority = {
  async run(payload: RunPayload) {
    const prompt = payload.input;
    const opts = payload.options || {};

    // 1) Modelo local
    try { return await localLLMGenerate(prompt, opts); } catch {}

    // 2) GPU gratuita
    try { return await freeGPUWorkerGenerate(prompt, opts); } catch {}

    // 3) Provedores gratuitos
    try { return await freeProviderGenerate(prompt, opts); } catch {}

    // 4) OpenAI (pago)
    return await openaiFallback(prompt, opts);
  },

  async *stream(payload: RunPayload) {
    // Estrutura de streaming: idealmente cada backend acima ofereceria SSE/Websocket.
    // Aqui exemplificamos stream via modelo local (que expÃµe SSE)
    const url = (process.env.LOCAL_MODEL_STREAM_URL || "http://localhost:7001/stream")
      + `?q=${encodeURIComponent(payload.input)}`;
    const res = await fetch(url, { method: "GET" });
    if (!res.ok || !res.body) throw new Error("stream-not-available");

    const reader = res.body.getReader();
    const decoder = new TextDecoder("utf-8");
    let done = false;

    while (!done) {
      const { value, done: d } = await reader.read();
      done = d;
      if (value) {
        const chunk = decoder.decode(value);
        yield chunk;
      }
    }
  }
};

ðŸ§© A10. server/routes/chat.ts
import type { Express, Request, Response } from "express";
import { ChatSchema } from "../schemas";
import { badRequest, ok, serverError } from "../utils/http";
import { reqLog } from "../utils/logger";
import { generateWithPriority } from "../llm/priority-orchestrator";

export function registerChatRoutes(app: Express) {
  app.post("/api/chat", async (req: Request, res: Response) => {
    const log = reqLog(req);
    const parsed = ChatSchema.safeParse(req.body);
    if (!parsed.success) return badRequest(res, parsed.error.flatten());

    try {
      const answer = await generateWithPriority.run(parsed.data);
      return ok(res, answer);
    } catch (error: unknown) {
      const msg = error instanceof Error ? error.message : "unknown-error";
      log.error({ msg, route: "/api/chat" });
      return serverError(res, msg);
    }
  });
}

ðŸ§© A11. server/routes/chat-stream.ts â€” SSE
import type { Express, Request, Response } from "express";
import { ChatSchema } from "../schemas";
import { reqLog } from "../utils/logger";
import { generateWithPriority } from "../llm/priority-orchestrator";

export function registerChatStream(app: Express) {
  app.get("/api/chat/stream", async (req: Request, res: Response) => {
    const log = reqLog(req);
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");

    try {
      const payload = ChatSchema.parse(JSON.parse(String(req.query.payload || "{}")));

      for await (const token of generateWithPriority.stream(payload)) {
        res.write(`data: ${JSON.stringify({ token })}\n\n`);
      }
      res.write("data: [DONE]\n\n");
    } catch (e: any) {
      const msg = e?.message || "stream-error";
      log.error({ msg, route: "/api/chat/stream" });
      res.write(`event: error\ndata: ${JSON.stringify({ error: msg })}\n\n`);
    } finally {
      res.end();
    }
  });
}

ðŸ§© A12. server/rag/kb-service.ts â€” ServiÃ§o de KB
// ImplementaÃ§Ã£o mÃ­nima: persistÃªncia no DB + integraÃ§Ã£o com indexaÃ§Ã£o
// Adapte para seu ORM/driver. Aqui estÃ¡ pseudo-cÃ³digo usando uma camada db abstrata.

type IngestLink = { url: string; namespaces: string[]; dedup: boolean };
type IngestFile = { name: string; mime: string; size: number; namespaces: string[]; hash?: string };
type Promote = { text: string; title?: string; suggestedNamespaces: string[]; submittedBy?: string };

export const kbService = {
  async ingestLink(data: IngestLink) {
    // 1) baixar HTML, extrair texto, normalizar
    // 2) salvar no DB como "pending curation"
    // 3) retornar id
    const id = await dbInsert("kb_ingest", { type: "link", ...data, status: "pending" });
    return id;
  },

  async ingestFile(data: IngestFile) {
    // 1) validar/armazenar metadados (o upload real pode estar em storage S3/Supabase)
    const id = await dbInsert("kb_ingest", { type: "file", ...data, status: "pending" });
    return id;
  },

  async promote(p: Promote) {
    // 1) cria registro final em kb_documents
    // 2) retorna id para indexaÃ§Ã£o
    const docId = await dbInsert("kb_documents", {
      title: p.title || p.text.slice(0, 80),
      text: p.text,
      namespaces: JSON.stringify(p.suggestedNamespaces),
      submittedBy: p.submittedBy || "system",
      createdAt: new Date()
    });
    return docId;
  },

  async remove(id: number) {
    await dbDelete("kb_documents", { id });
    // Remover dos Ã­ndices (VectorStore remove?) â€” implementar
  }
};

// SimulaÃ§Ãµes de acesso a DB (substitua pela sua camada real)
async function dbInsert(table: string, data: any) {
  // implemente via Supabase/Prisma/Knex/Drizzle
  return Math.floor(Math.random() * 1e9);
}
async function dbDelete(_table: string, _where: any) { return; }

ðŸ§© A13. server/rag/knowledge-indexer.ts â€” Fila e indexaÃ§Ã£o
import { vectorStore } from "./vector-store";
import { embed } from "./text-embedder"; // sua funÃ§Ã£o de embeddings
import { getDocumentById } from "./repo"; // acesse texto do doc

const queue: number[] = [];
let running = false;

export function scheduleIndex(documentId: number) {
  queue.push(documentId);
  if (!running) run();
}

async function run() {
  running = true;
  while (queue.length) {
    const id = queue.shift()!;
    try {
      const doc = await getDocumentById(id); // { id, text, namespaces, ... }
      const chunks = chunkText(doc.text);
      const vectors = await Promise.all(chunks.map(c => embed(c.text)));
      vectors.forEach((v, i) => vectorStore.addVector(doc.id * 10_000 + i, v, { text: chunks[i].text, documentId: doc.id, namespaces: doc.namespaces }));
      vectorStore.save(); // persistÃªncia (snapshot)
    } catch (e) {
      console.error("[Indexer] fail", id, (e as Error).message);
    }
  }
  running = false;
}

function chunkText(text: string, max = 1200) {
  const out: { text: string }[] = [];
  let i = 0;
  while (i < text.length) {
    out.push({ text: text.slice(i, i + max) });
    i += max;
  }
  return out;
}

ðŸ§© A14. server/rag/vector-store.ts â€” VectorStore com snapshot
import fs from "fs";
import path from "path";

type Meta = { text: string; documentId: number; namespaces?: string[]; [k: string]: any };

class VectorStore {
  private vectors = new Map<number, number[]>();
  private metadata = new Map<number, Meta>();
  private readonly snapshotPath = process.env.VECTOR_SNAPSHOT_PATH || "./data/vectorstore.snapshot.json";

  load(): void {
    if (!fs.existsSync(this.snapshotPath)) return;
    const raw = JSON.parse(fs.readFileSync(this.snapshotPath, "utf-8"));
    this.vectors = new Map<number, number[]>(Object.entries(raw.vectors).map(([k,v]) => [Number(k), v as number[]]));
    this.metadata = new Map<number, Meta>(Object.entries(raw.metadata).map(([k,v]) => [Number(k), v as Meta]));
    console.log(`[VectorStore] Loaded snapshot (${this.vectors.size} vectors)`);
  }

  save(): void {
    fs.mkdirSync(path.dirname(this.snapshotPath), { recursive: true });
    const out = {
      vectors: Object.fromEntries(this.vectors.entries()),
      metadata: Object.fromEntries(this.metadata.entries()),
    };
    fs.writeFileSync(this.snapshotPath, JSON.stringify(out));
    console.log("[VectorStore] Snapshot saved");
  }

  addVector(id: number, vec: number[], meta: Meta) {
    this.vectors.set(id, normalize(vec));
    this.metadata.set(id, meta);
  }

  similaritySearch(query: number[], k = 8, filter?: (m: Meta)=>boolean) {
    const q = normalize(query);
    const scored: { id: number; score: number; meta: Meta }[] = [];
    for (const [id, v] of this.vectors.entries()) {
      const meta = this.metadata.get(id)!;
      if (filter && !filter(meta)) continue;
      const score = dot(q, v); // cos porque normalizamos
      scored.push({ id, score, meta });
    }
    return scored.sort((a,b)=>b.score-a.score).slice(0, k);
  }
}

export const vectorStore = new VectorStore();

process.on("SIGTERM", () => { try { vectorStore.save(); } catch {} });

function dot(a: number[], b: number[]) {
  let s = 0; for (let i=0;i<a.length;i++) s += a[i]*b[i]; return s;
}
function norm(a: number[]) {
  let s = 0; for (let i=0;i<a.length;i++) s += a[i]*a[i]; return Math.sqrt(s);
}
function normalize(a: number[]) {
  const n = norm(a) || 1; return a.map(x => x/n);
}


Chame vectorStore.load() no boot (ex.: no server/index.ts apÃ³s iniciar DB).

ðŸ§© A15. server/metrics/exporter.ts â€” MÃ©tricas (JSON/Prometheus)
type Counters = Record<string, number>;
const counters: Counters = {
  requests_total: 0,
  chat_requests_total: 0,
  chat_streams_total: 0,
  kb_promotions_total: 0,
  fallback_calls_total: 0
};

export const metricsExporter = {
  inc(name: keyof typeof counters, value = 1) {
    counters[name] = (counters[name] || 0) + value;
  },
  async json() {
    return { ...counters, timestamp: Date.now() };
  },
  async prom() {
    return Object.entries(counters).map(([k,v]) => `# TYPE ${k} counter\n${k} ${v}`).join("\n");
  }
};


Use metricsExporter.inc('chat_requests_total') dentro das rotas para contar.

ðŸ§© A16. server/routes/metrics.ts â€” Expor mÃ©tricas
import type { Express, Request, Response } from "express";
import { ok } from "../utils/http";
import { metricsExporter } from "../metrics/exporter";

export function registerMetricsRoutes(app: Express) {
  app.get("/metrics", async (_req: Request, res: Response) => {
    const json = await metricsExporter.json();
    return ok(res, json);
  });
}

ðŸ§© A17. server/policy/service.ts â€” PolÃ­ticas
type PolicyFlags = { enableModeration?: boolean; enableWebSearch?: boolean; allowExternalAPIs?: boolean };
type PolicyUpdate = { preset: string; flags?: PolicyFlags };

let currentPolicy: PolicyUpdate = { preset: "UNRESTRICTED", flags: { enableModeration: false } };

export const policyService = {
  get() { return currentPolicy; },
  update(p: PolicyUpdate) {
    currentPolicy = { ...currentPolicy, ...p, flags: { ...currentPolicy.flags, ...p.flags } };
    // persistir no DB se desejar
    return currentPolicy;
  }
};

ðŸ§© A18. server/routes/policy.ts â€” Rotas de Policy
import type { Express, Request, Response } from "express";
import { PolicyUpdateSchema } from "../schemas";
import { badRequest, ok, serverError } from "../utils/http";
import { reqLog } from "../utils/logger";
import { policyService } from "../policy/service";

export function registerPolicyRoutes(app: Express) {
  app.get("/policy", (_req: Request, res: Response) => ok(res, policyService.get()));

  app.post("/policy/update", async (req: Request, res: Response) => {
    const log = reqLog(req);
    const parsed = PolicyUpdateSchema.safeParse(req.body);
    if (!parsed.success) return badRequest(res, parsed.error.flatten());
    try {
      const result = policyService.update(parsed.data);
      return ok(res, result);
    } catch (e: any) {
      log.error({ msg: e?.message || "policy-update-error" });
      return serverError(res, "policy-update-error");
    }
  });
}

ðŸ§© A19. server/routes/policy-audit.ts â€” Audit Trail (mÃ­nimo)
import type { Express, Request, Response } from "express";
import { ok } from "../utils/http";

type AuditLog = { at: number; actor: string; action: string; data?: any };
const audit: AuditLog[] = [];

export function addAudit(actor: string, action: string, data?: any) {
  audit.push({ at: Date.now(), actor, action, data });
  if (audit.length > 1000) audit.shift();
}

export function registerPolicyAudit(app: Express) {
  app.get("/api/admin/policy/audit", (_req: Request, res: Response) => ok(res, audit.slice(-100)));
}


Integre addAudit() em pontos sensÃ­veis (policy update, namespace create, etc.).

ðŸ§© A20. server/agent/service.ts â€” Agents/Namespaces
type Namespace = { id: string; label: string; description?: string; createdAt: number };
const namespaces = new Map<string, Namespace>();

export const agentsService = {
  listNamespaces() {
    return Array.from(namespaces.values());
  },
  createNamespace(data: Partial<Namespace>) {
    const id = (data.id || `ns_${Date.now()}`).toString();
    const ns: Namespace = { id, label: data.label || id, description: data.description || "", createdAt: Date.now() };
    namespaces.set(id, ns);
    return ns;
  }
};

ðŸ§© A21. server/routes/agents.ts
import type { Express, Request, Response } from "express";
import { ok, badRequest, serverError } from "../utils/http";
import { agentsService } from "../agent/service";
import { reqLog } from "../utils/logger";

export function registerAgentRoutes(app: Express) {
  app.get("/agents/namespaces", async (_req: Request, res: Response) => {
    const data = await agentsService.listNamespaces();
    return ok(res, data);
  });

  app.post("/agents/namespaces", async (req: Request, res: Response) => {
    const log = reqLog(req);
    try {
      if (!req.body?.label) return badRequest(res, "label-required");
      const data = await agentsService.createNamespace(req.body);
      return ok(res, data);
    } catch (e: any) {
      log.error({ msg: e?.message || "namespace-create-error" });
      return serverError(res, "namespace-create-error");
    }
  });
}

ðŸ§© A22. server/curation/service.ts â€” Curadoria
type CurationItem = { id: string; text: string; source: string; suggestedNamespaces: string[]; status: "pending"|"approved"|"rejected" };

const queue: CurationItem[] = [];

export const curationService = {
  listPending() {
    return queue.filter(q => q.status === "pending");
  },
  enqueue(item: Omit<CurationItem,"status">) {
    const it: CurationItem = { ...item, status: "pending" };
    queue.push(it);
    return it;
  },
  applyAction({ itemId, action, reason }: { itemId: string; action: "approve"|"reject"; reason?: string }) {
    const it = queue.find(q => q.id === itemId);
    if (!it) throw new Error("item-not-found");
    it.status = action === "approve" ? "approved" : "rejected";
    return { ok: true, item: it, reason };
  }
};

ðŸ§© A23. server/routes/curation.ts
import type { Express, Request, Response } from "express";
import { ok, badRequest, serverError } from "../utils/http";
import { reqLog } from "../utils/logger";
import { CurationActionSchema } from "../schemas";
import { curationService } from "../curation/service";
import { scheduleIndex } from "../rag/knowledge-indexer";

export function registerCurationRoutes(app: Express) {
  app.get("/curation/pending", async (_req: Request, res: Response) => {
    const items = await curationService.listPending();
    return ok(res, items);
  });

  app.post("/curation/action", async (req: Request, res: Response) => {
    const log = reqLog(req);
    const parsed = CurationActionSchema.safeParse(req.body);
    if (!parsed.success) return badRequest(res, parsed.error.flatten());
    try {
      const result = await curationService.applyAction(parsed.data);
      if (parsed.data.action === "approve" && result?.item) {
        // exemplo: gerar docId e indexar
        const docId = Number(result.item.id.replace(/\D/g,"")) || Date.now();
        await scheduleIndex(docId);
      }
      return ok(res, result);
    } catch (e: any) {
      log.error({ msg: e?.message || "curation-action-error" });
      return serverError(res, "curation-action-error");
    }
  });
}

ðŸ§© A24. server/routes/kb.ts â€” KB (ingest/promote)
import type { Express, Request, Response } from "express";
import { IngestLinkSchema, IngestFileSchema, PromoteSchema } from "../schemas";
import { badRequest, ok, created, serverError } from "../utils/http";
import { reqLog } from "../utils/logger";
import { scheduleIndex } from "../rag/knowledge-indexer";
import { kbService } from "../rag/kb-service";

export function registerKbRoutes(app: Express) {
  app.post("/kb/ingest/link", async (req: Request, res: Response) => {
    const log = reqLog(req);
    const parsed = IngestLinkSchema.safeParse(req.body);
    if (!parsed.success) return badRequest(res, parsed.error.flatten());
    try {
      const id = await kbService.ingestLink(parsed.data);
      return created(res, { id });
    } catch (e: any) {
      log.error({ msg: e?.message || "ingest-link-error" });
      return serverError(res, "ingest-link-error");
    }
  });

  app.post("/kb/ingest/file", async (req: Request, res: Response) => {
    const log = reqLog(req);
    const parsed = IngestFileSchema.safeParse(req.body);
    if (!parsed.success) return badRequest(res, parsed.error.flatten());
    try {
      const id = await kbService.ingestFile(parsed.data);
      return created(res, { id });
    } catch (e: any) {
      log.error({ msg: e?.message || "ingest-file-error" });
      return serverError(res, "ingest-file-error");
    }
  });

  app.post("/kb/promote", async (req: Request, res: Response) => {
    const log = reqLog(req);
    const parsed = PromoteSchema.safeParse(req.body);
    if (!parsed.success) return badRequest(res, parsed.error.flatten());
    try {
      const docId = await kbService.promote(parsed.data);
      await scheduleIndex(docId); // indexaÃ§Ã£o incremental + snapshot
      return created(res, { documentId: docId });
    } catch (e: any) {
      log.error({ msg: e?.message || "kb-promote-error" });
      return serverError(res, "kb-promote-error");
    }
  });

  app.delete("/kb/:id", async (req: Request, res: Response) => {
    try {
      await kbService.remove(Number(req.params.id));
      return ok(res, { removed: true });
    } catch {
      return serverError(res, "kb-remove-error");
    }
  });
}

âœ… ConclusÃ£o do ApÃªndice A (Backend)

Com os arquivos A1â†’A24 acima, vocÃª tem:

Server Express/TS endurecido (helmet, rate-limit, logger, error-handler).

Rotas moduladas, com Zod e envelopes HTTP.

SSE para streaming token-a-token.

VectorStore persistente (snapshot) + indexaÃ§Ã£o incremental.

ServiÃ§os de Policy, Agents/Namespaces, Curation e KB.

MÃ©tricas exportÃ¡veis.