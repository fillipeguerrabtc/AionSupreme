# Guia de Configura√ß√£o de Workers GPU para Gera√ß√£o Profissional de V√≠deo

‚ö†Ô∏è **NOTA**: Este guia √© para **GERA√á√ÉO DE V√çDEO** (RunPod/Modal - PAGO)

Para **INFER√äNCIA/TREINO GR√ÅTIS** (Colab/Kaggle), veja: [SETUP_GPU_WORKERS.md](./SETUP_GPU_WORKERS.md)

---

## üé¨ Vis√£o Geral

AION usa **workers apoiados por GPU** para gerar v√≠deos profissionais de qualidade cinematogr√°fica usando modelos open-source:
- **Open-Sora 1.2** (prim√°rio) - Text-to-video de alta qualidade
- **AnimateDiff + Stable Video Diffusion** (secund√°rio)
- **ModelScope** (fallback terci√°rio)

**Diferen√ßas:**
| Recurso | Gera√ß√£o de V√≠deo (Este Guia) | Infer√™ncia/Treinamento (SETUP_GPU_WORKERS.md) |
|---------|------------------------------|-----------------------------------------------|
| Uso | Gera√ß√£o de v√≠deos profissionais | Infer√™ncia LLM + Treinamento LoRA |
| Plataforma | RunPod, Modal (pago) | Google Colab, Kaggle (gr√°tis) |
| GPU | RTX 4090, A6000 (24GB+) | T4, P100 (15-16GB) |
| Custo | ~$0.40-0.80/hora | $0 (100% gr√°tis) |

## üìã Pr√©-requisitos

- GPU NVIDIA com ‚â•16GB VRAM (24GB recomendado para 4K)
- CUDA 11.8+ e cuDNN
- Docker (recomendado) ou Python 3.10+
- Conta RunPod/Modal (para implanta√ß√£o em nuvem) OU GPU auto-hospedada

---

## üöÄ In√≠cio R√°pido: Implantar Worker no RunPod

### 1. Criar Conta RunPod
Visite https://runpod.io e crie uma conta. Adicione cr√©ditos GPU (~$10 para teste).

### 2. Implantar Template de Worker

```bash
# Clonar reposit√≥rio do worker
git clone https://github.com/sua-org/aion-video-worker.git
cd aion-video-worker

# Construir imagem Docker
docker build -t aion-video-worker:latest .

# Enviar para Docker Hub (ou registro de cont√™iner RunPod)
docker tag aion-video-worker:latest seu-dockerhub/aion-video-worker:latest
docker push seu-dockerhub/aion-video-worker:latest
```

### 3. Configurar Pod RunPod

1. V√° para Console RunPod ‚Üí Pods ‚Üí Deploy New Pod
2. Selecione **GPU**: RTX 4090 ou A6000 (48GB VRAM recomendado)
3. Imagem do Cont√™iner: `seu-dockerhub/aion-video-worker:latest`
4. Disco do Cont√™iner: 50GB m√≠nimo
5. Volume: 100GB para pesos do modelo
6. Expor Porta: `8000` (HTTP)
7. Vari√°veis de Ambiente:
   ```
   MODEL=open-sora
   WORKERS=1
   WEBHOOK_SECRET=sua-chave-secreta
   ```

### 4. Conectar AION ao Worker

No seu projeto Replit, adicione vari√°vel de ambiente:

```bash
VIDEO_WORKER_URL=https://seu-pod-id-8000.proxy.runpod.net/generate
```

Reinicie seu servidor AION.

---

## üèóÔ∏è Arquitetura do Worker

### Entrada (POST /generate)
```json
{
  "job_id": 123,
  "prompt": "Um drag√£o majestoso voando sobre montanhas ao p√¥r do sol",
  "parameters": {
    "duration": 30,
    "fps": 24,
    "resolution": "1080p",
    "style": "cinematic",
    "scenes": 3,
    "audio": true,
    "model": "open-sora"
  },
  "callback_url": "https://seu-aion.replit.app/api/videos/webhook"
}
```

### Pipeline de Processamento
1. **Planejamento de Cenas** - Dividir prompt em sequ√™ncias multi-shot
2. **Gera√ß√£o de V√≠deo** - S√≠ntese Open-Sora/AnimateDiff
3. **Montagem** - Concatena√ß√£o de cenas FFmpeg
4. **Upscaling** - Upscaling temporal Real-ESRGAN
5. **Interpola√ß√£o de Frames** - RIFE para movimento suave
6. **S√≠ntese de √Åudio** - TTS ElevenLabs/Bark + m√∫sica
7. **Sincroniza√ß√£o de √Åudio** - Alinhar narra√ß√£o com v√≠deo

### Sa√≠da (POST callback_url/webhook)
```json
{
  "job_id": 123,
  "status": "completed",
  "video_url": "https://storage.runpod.io/videos/abc123.mp4",
  "thumbnail_url": "https://storage.runpod.io/thumbs/abc123.jpg",
  "duration": 30.2,
  "resolution": "1920x1080",
  "fps": 24,
  "size_bytes": 45678901,
  "metadata": {
    "scenes": 3,
    "transitions": ["fade", "dissolve"],
    "quality_score": 92.5
  }
}
```

---

## üê≥ Implementa√ß√£o do Worker Docker

### Dockerfile
```dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y \
    python3.10 python3-pip git ffmpeg \
    libsm6 libxext6 libxrender-dev

# Instalar pacotes Python
RUN pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
RUN pip3 install diffusers transformers accelerate xformers
RUN pip3 install opencv-python pillow numpy scipy
RUN pip3 install fastapi uvicorn httpx

# Clonar modelos
RUN git clone https://huggingface.co/hpcai-tech/Open-Sora /models/open-sora
RUN git clone https://huggingface.co/guoyww/animatediff /models/animatediff

# Copiar c√≥digo do worker
WORKDIR /app
COPY worker.py .
COPY requirements.txt .
RUN pip3 install -r requirements.txt

EXPOSE 8000
CMD ["uvicorn", "worker:app", "--host", "0.0.0.0", "--port", "8000"]
```

### worker.py (Exemplo)
```python
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel
import httpx
import asyncio
from typing import Optional

app = FastAPI()

class VideoRequest(BaseModel):
    job_id: int
    prompt: str
    parameters: dict
    callback_url: str

@app.post("/generate")
async def generate_video(request: VideoRequest, background_tasks: BackgroundTasks):
    # Iniciar gera√ß√£o em background
    background_tasks.add_task(process_video, request)
    return {"status": "processing", "job_id": request.job_id}

async def process_video(request: VideoRequest):
    try:
        # 1. Carregar modelo (Open-Sora)
        from opensora.models import OpenSoraModel
        model = OpenSoraModel.from_pretrained("/models/open-sora")
        
        # 2. Gerar v√≠deo
        video_path = await model.generate(
            prompt=request.prompt,
            duration=request.parameters.get("duration", 30),
            fps=request.parameters.get("fps", 24),
            resolution=request.parameters.get("resolution", "1080p"),
        )
        
        # 3. Upload para storage
        video_url = await upload_to_storage(video_path)
        
        # 4. Callback para AION
        async with httpx.AsyncClient() as client:
            await client.post(
                request.callback_url,
                json={
                    "job_id": request.job_id,
                    "status": "completed",
                    "video_url": video_url,
                    "duration": 30.0,
                    "resolution": "1920x1080",
                    "fps": 24,
                }
            )
    except Exception as e:
        # Callback com erro
        async with httpx.AsyncClient() as client:
            await client.post(
                request.callback_url,
                json={
                    "job_id": request.job_id,
                    "status": "failed",
                    "error": str(e),
                }
            )

async def upload_to_storage(video_path: str) -> str:
    # Upload para S3/R2/RunPod Storage
    # Retornar URL p√∫blica
    pass
```

---

## üñ•Ô∏è Configura√ß√£o Auto-Hospedada (Avan√ßado)

### Requisitos
- Ubuntu 22.04 LTS
- GPU NVIDIA (RTX 3090, 4090, A6000, etc.)
- 32GB+ RAM
- 500GB+ SSD

### Instala√ß√£o
```bash
# Instalar CUDA
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update
sudo apt-get install cuda-11-8

# Instalar cuDNN
# Baixar do site da NVIDIA
sudo dpkg -i cudnn-local-repo-ubuntu2204-8.9.0.131_1.0-1_amd64.deb

# Instalar ambiente Python
sudo apt install python3.10 python3-pip python3-venv
python3 -m venv venv
source venv/bin/activate

# Instalar depend√™ncias
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install diffusers transformers accelerate xformers
pip install fastapi uvicorn httpx pillow opencv-python

# Baixar modelos
git lfs install
git clone https://huggingface.co/hpcai-tech/Open-Sora models/open-sora
git clone https://huggingface.co/guoyww/animatediff models/animatediff

# Executar worker
uvicorn worker:app --host 0.0.0.0 --port 8000
```

### Expor com ngrok (para teste)
```bash
ngrok http 8000
# Usar URL ngrok como VIDEO_WORKER_URL no AION
```

---

## üìä Compara√ß√£o de Modelos

| Modelo | Qualidade | Velocidade | VRAM | Melhor Para |
|--------|-----------|------------|------|-------------|
| **Open-Sora 1.2** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | M√©dio | 24GB | Cinematogr√°fico, realista |
| **AnimateDiff** | ‚≠ê‚≠ê‚≠ê‚≠ê | R√°pido | 16GB | Animado, estilizado |
| **ModelScope** | ‚≠ê‚≠ê‚≠ê | Muito R√°pido | 12GB | Rascunhos r√°pidos |

---

## üîß Solu√ß√£o de Problemas

### Out of Memory (OOM)
- Reduzir resolu√ß√£o: 4K ‚Üí 1080p ‚Üí 720p
- Reduzir dura√ß√£o: 120s ‚Üí 60s ‚Üí 30s
- Habilitar offloading do modelo: `model.enable_model_cpu_offload()`

### Gera√ß√£o Lenta
- Usar precis√£o mista: `torch.autocast("cuda")`
- Habilitar xformers: `model.enable_xformers_memory_efficient_attention()`
- Reduzir FPS: 30 ‚Üí 24 ‚Üí 15

### Worker N√£o Acess√≠vel
- Verificar regras de firewall (porta 8000 aberta)
- Verificar status do proxy ngrok/RunPod
- Testar com: `curl http://worker-url/health`

---

## üí° Estimativas de Custo

### RunPod (GPU Cloud)
- RTX 4090: ~$0.40/hora
- A6000 (48GB): ~$0.80/hora
- Gera√ß√£o de v√≠deo de 30s: ~2-5 minutos = $0.01-0.05/v√≠deo

### Auto-Hospedado
- RTX 4090: ~$1.600 √∫nico
- Eletricidade: ~$0.50/dia (24/7)
- Break-even: ~3.200 v√≠deos

---

## üìö Recursos

- Open-Sora: https://github.com/hpcaitech/Open-Sora
- AnimateDiff: https://github.com/guoyww/AnimateDiff
- Docs RunPod: https://docs.runpod.io
- Docs Modal: https://modal.com/docs

---

## ‚úÖ Pr√≥ximos Passos

1. **Implantar Worker**: RunPod ou auto-hospedado
2. **Definir VIDEO_WORKER_URL**: Vari√°vel de ambiente no AION
3. **Testar**: POST /api/videos/generate com prompt simples
4. **Monitorar**: Verificar /api/videos/jobs/:id para status
5. **Escalar**: Adicionar mais workers para processamento paralelo
