/**
 * Vector Store - Busca sem√¢ntica baseada em FAISS
 * 
 * Conforme PDFs: FAISS/Milvus com HNSW (M‚âà64, efSearch‚âà128) + IVF-PQ
 * Implementa A-NNS com complexidade O(log N)
 * 
 * Nota: Usando FAISS em mem√≥ria (implementa√ß√£o JavaScript) para Replit.
 * Para produ√ß√£o no Google Colab, usar FAISS Python com suporte GPU.
 */

import { storage } from "../storage";
import { embedder } from "./embedder";
import type { Embedding } from "@shared/schema";
import { usageTracker } from "../services/usage-tracker";
import fs from "fs/promises";
import fsSync from "fs";
import path from "path";

interface SearchResult {
  id: number;
  score: number; // Similaridade cosseno
  chunkText: string;
  metadata?: Record<string, any>;
  documentId: number;
  attachments?: Array<{
    type: 'image' | 'video' | 'pdf' | 'audio' | 'document';
    url: string;
    filename?: string;
    mimeType?: string;
    size?: number;
    description?: string;
  }>;
}

/**
 * Vector store simples em mem√≥ria similar ao FAISS
 * Para produ√ß√£o, substituir por FAISS real (faiss-node ou microsservi√ßo Python)
 */
export class VectorStore {
  private vectors: Map<number, number[]> = new Map(); // embedding_id -> vetor
  private metadata: Map<number, { text: string; documentId: number; meta?: any }> = new Map();
  
  /**
   * Indexar embeddings de um documento
   * Conforme PDFs: Vetores normalizados √™_{i,j}=e_{i,j}/||e_{i,j}||
   */
  async indexDocument(documentId: number): Promise<void> {
    console.log(`[VectorStore] Indexando documento ${documentId}...`);
    
    // Obter todos os embeddings deste documento
    const embeddings = await storage.getEmbeddingsByDocument(documentId);
    
    // Add to in-memory index
    for (const emb of embeddings) {
      this.vectors.set(emb.id, emb.embedding as number[]);
      this.metadata.set(emb.id, {
        text: emb.chunkText,
        documentId: emb.documentId,
        meta: emb.metadata,
      });
    }
    
    console.log(`[VectorStore] Indexed ${embeddings.length} chunks for document ${documentId}`);
  }

  /**
   * Indexar todos os embeddings da base de conhecimento
   */
  async indexTenant(limit: number = 10000): Promise<void> {
    console.log(`[VectorStore] Indexando base de conhecimento...`);
    
    const embeddings = await storage.getEmbeddings(limit);
    
    for (const emb of embeddings) {
      this.vectors.set(emb.id, emb.embedding as number[]);
      this.metadata.set(emb.id, {
        text: emb.chunkText,
        documentId: emb.documentId,
        meta: emb.metadata,
      });
    }
    
    console.log(`[VectorStore] Indexed ${embeddings.length} embeddings`);
  }

  /**
   * Busca sem√¢ntica com similaridade cosseno
   * Conforme PDFs: sim(q,d)=E(q)¬∑E(d)/(||E(q)||||E(d)||)
   * Retorna top-k resultados com complexidade O(N) (for√ßa bruta por enquanto)
   */
  async search(
    queryEmbedding: number[],
    k: number = 10,
    filter?: { documentId?: number; namespaces?: string[] }
  ): Promise<SearchResult[]> {
    const results: Array<{ id: number; score: number }> = [];
    
    // Calcular similaridade com todos os vetores
    for (const [id, vector] of Array.from(this.vectors.entries())) {
      // Aplicar filtros
      const meta = this.metadata.get(id);
      if (filter?.documentId && meta?.documentId !== filter.documentId) {
        continue;
      }
      
      // CR√çTICO: Filtrar por namespaces se especificado
      if (filter?.namespaces && filter.namespaces.length > 0) {
        const docNamespace = meta?.meta?.namespace as string | undefined;
        
        // MONITORAMENTO: Registrar se embedding est√° sem metadata de namespace
        if (!docNamespace) {
          console.warn(`[VectorStore] ‚ö†Ô∏è  Embedding ID ${id} sem metadata de namespace (documentId: ${meta?.documentId})`);
        }
        
        // Normalizar mai√∫sculas/min√∫sculas para fontes heterog√™neas (query e documento)
        const normalizedDocNamespace = docNamespace?.toLowerCase();
        const normalizedFilterNamespaces = filter.namespaces.map(ns => ns.toLowerCase());
        
        // Verificar se namespace do documento corresponde a algum dos namespaces permitidos
        // Suporte a wildcard "*" para acessar todos os namespaces
        const hasWildcard = normalizedFilterNamespaces.includes("*");
        const hasMatchingNamespace = normalizedDocNamespace && normalizedFilterNamespaces.includes(normalizedDocNamespace);
        
        if (!hasWildcard && !hasMatchingNamespace) {
          continue; // Pular este documento - n√£o est√° nos namespaces permitidos
        }
      }
      
      // Similaridade cosseno (vetores j√° est√£o normalizados)
      const score = embedder.cosineSimilarity(queryEmbedding, vector);
      results.push({ id, score });
    }
    
    // Sort by score descending
    results.sort((a, b) => b.score - a.score);
    
    // Take top-k
    const topK = results.slice(0, k);
    
    // Build result objects
    return topK.map(({ id, score }) => {
      const meta = this.metadata.get(id)!;
      return {
        id,
        score,
        chunkText: meta.text,
        documentId: meta.documentId,
        metadata: meta.meta,
      };
    });
  }

  /**
   * Remove document from index
   */
  async removeDocument(documentId: number): Promise<void> {
    const toRemove: number[] = [];
    
    for (const [id, meta] of Array.from(this.metadata.entries())) {
      if (meta.documentId === documentId) {
        toRemove.push(id);
      }
    }
    
    for (const id of toRemove) {
      this.vectors.delete(id);
      this.metadata.delete(id);
    }
    
    console.log(`[VectorStore] Removed ${toRemove.length} chunks for document ${documentId}`);
  }

  /**
   * Clear all vectors (useful for re-indexing)
   */
  clear(): void {
    this.vectors.clear();
    this.metadata.clear();
    console.log("[VectorStore] Cleared all vectors");
  }

  /**
   * Get statistics
   */
  getStats(): { totalVectors: number; dimensions: number } {
    const firstVector = this.vectors.values().next().value;
    return {
      totalVectors: this.vectors.size,
      dimensions: firstVector ? firstVector.length : 0,
    };
  }

  /**
   * üíæ FASE 1 - Vector Store Persistente
   * Salva snapshot do index em disco para persistir entre restarts
   */
  private snapshotPath = process.env.VECTOR_SNAPSHOT_PATH || "./data/vectorstore.snapshot.json";

  async save(): Promise<void> {
    try {
      const snapshot = {
        vectors: Object.fromEntries(this.vectors.entries()),
        metadata: Object.fromEntries(this.metadata.entries()),
        timestamp: new Date().toISOString(),
        stats: this.getStats()
      };

      const dir = path.dirname(this.snapshotPath);
      await fs.mkdir(dir, { recursive: true });
      await fs.writeFile(this.snapshotPath, JSON.stringify(snapshot, null, 2));
      console.log(`[VectorStore] üíæ Snapshot salvo: ${this.vectors.size} vectors (${this.snapshotPath})`);
    } catch (error) {
      console.error("[VectorStore] ‚ùå Erro ao salvar snapshot:", error);
    }
  }

  async load(): Promise<void> {
    try {
      try {
        await fs.access(this.snapshotPath);
      } catch {
        console.log("[VectorStore] ‚ÑπÔ∏è  Nenhum snapshot encontrado, iniciando com index vazio");
        return;
      }

      const data = await fs.readFile(this.snapshotPath, "utf-8");
      const snapshot = JSON.parse(data);

      this.vectors = new Map(Object.entries(snapshot.vectors).map(([k, v]) => [Number(k), v as number[]]));
      this.metadata = new Map(Object.entries(snapshot.metadata).map(([k, v]) => [Number(k), v as any]));

      console.log(`[VectorStore] ‚úÖ Snapshot carregado: ${this.vectors.size} vectors (salvo em ${snapshot.timestamp})`);
    } catch (error) {
      console.error("[VectorStore] ‚ùå Erro ao carregar snapshot:", error);
      console.log("[VectorStore] ‚ö†Ô∏è  Iniciando com index vazio");
      this.vectors.clear();
      this.metadata.clear();
    }
  }
}

// Singleton instance
export const vectorStore = new VectorStore();

/**
 * High-level RAG operations
 */
export class RAGService {
  /**
   * Index a document (extract text, chunk, embed, store)
   */
  async indexDocument(
    documentId: number,
    text: string,
    metadata?: Record<string, any>
  ): Promise<void> {
    console.log(`[RAG] Indexing document ${documentId}...`);
    
    // Update document status
    await storage.updateDocument(documentId, {
      status: "processing",
      extractedText: text,
    });
    
    try {
      // Process document (chunk + embed)
      const results = await embedder.processDocument(text, {
        maxChunkSize: 512,
        overlapSize: 128,
        metadata,
      });
      
      // Save embeddings to database
      const embeddingRecords = results.map((result, idx) => ({
        documentId,
        chunkIndex: idx,
        chunkText: result.chunk.text,
        chunkTokens: result.chunk.tokens,
        embedding: result.embedding,
        embeddingDim: result.embedding.length,
        metadata: result.chunk.metadata,
      }));
      
      await storage.createEmbeddingsBatch(embeddingRecords);
      
      // Update document status to 'indexed' BEFORE indexing in vector store
      // This is critical because vectorStore.indexDocument() queries embeddings
      // and storage.getEmbeddingsByDocument() only returns embeddings for status='indexed'
      await storage.updateDocument(documentId, {
        status: "indexed",
      });
      
      // Index in vector store (now embeddings will be found)
      await vectorStore.indexDocument(documentId);
      
      console.log(`[RAG] Successfully indexed document ${documentId} (${results.length} chunks)`);
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error(`[RAG] Error indexing document ${documentId}:`, error);
      
      await storage.updateDocument(documentId, {
        status: "failed",
        errorMessage: errorMessage,
      });
      
      throw error;
    }
  }

  /**
   * Search knowledge base
   * As per PDFs: Retrieval with cosine similarity
   * MULTIMODAL: Returns attachments from source documents
   */
  async search(
    query: string,
    options: {
      k?: number;
      documentId?: number;
      namespaces?: string[];
    } = {}
  ): Promise<SearchResult[]> {
    const k = options.k || 10;
    
    // Generate query embedding
    const [queryEmbedding] = await embedder.generateEmbeddings(
      [{ text: query, index: 0, tokens: Math.ceil(query.length / 4) }]
    );
    
    // Search vector store with namespace filtering
    const results = await vectorStore.search(
      queryEmbedding.embedding,
      k,
      {
        documentId: options.documentId,
        namespaces: options.namespaces,
      }
    );
    
    // MULTIMODAL + HEALTHY FORGETTING: Fetch attachments + apply temporal degradation
    const uniqueDocIds = Array.from(new Set(results.map(r => r.documentId)));
    const documentAttachments = new Map<number, any[]>();
    const documentCreatedAt = new Map<number, Date>();
    
    for (const docId of uniqueDocIds) {
      const doc = await storage.getDocument(docId);
      if (doc) {
        if (doc.attachments && doc.attachments.length > 0) {
          documentAttachments.set(docId, doc.attachments);
        }
        if (doc.createdAt) {
          documentCreatedAt.set(docId, doc.createdAt);
        }
      }
    }
    
    // HEALTHY FORGETTING: Apply temporal degradation (freshness boost)
    // Recent documents get higher priority, old documents gradually decay
    const now = new Date();
    const AGE_WEIGHT = 0.3; // 30% max degradation
    const MAX_AGE_DAYS = 1825; // 5 years
    
    const resultsWithFreshness = results.map(result => {
      const createdAt = documentCreatedAt.get(result.documentId);
      let freshnessFactor = 1.0;
      
      if (createdAt) {
        // Normalize to Date instance (handles both Date and ISO string)
        const createdAtDate = createdAt instanceof Date ? createdAt : new Date(createdAt);
        
        // Guard against invalid dates
        if (!isNaN(createdAtDate.getTime())) {
          const ageInDays = (now.getTime() - createdAtDate.getTime()) / (1000 * 60 * 60 * 24);
          const ageRatio = Math.min(ageInDays / MAX_AGE_DAYS, 1); // Cap at 1.0
          freshnessFactor = 1 - (AGE_WEIGHT * ageRatio);
        }
      }
      
      return {
        ...result,
        attachments: documentAttachments.get(result.documentId),
        originalScore: result.score,
        freshnessFactor,
        score: result.score * freshnessFactor, // Apply temporal decay
      };
    });
    
    // Re-sort by adjusted score (freshness-aware ranking)
    const enrichedResults = resultsWithFreshness.sort((a, b) => b.score - a.score);
    
    console.log(`[RAG] Search completed: ${results.length} results, ${documentAttachments.size} docs with attachments, freshness applied`);
    
    // Track namespace usage for telemetry
    if (options.namespaces && options.namespaces.length > 0) {
      for (const namespaceName of options.namespaces) {
        usageTracker.trackNamespaceSearch(
          namespaceName,
          namespaceName,
          { query, resultsCount: results.length }
        );
      }
    }
    
    return enrichedResults;
  }

  /**
   * Re-index entire knowledge base
   */
  async reindexTenant(): Promise<void> {
    console.log(`[RAG] Re-indexing knowledge base...`);
    
    // Clear existing vectors
    vectorStore.clear();
    
    // Get all documents
    const documents = await storage.getDocuments(10000);
    
    let indexed = 0;
    let failed = 0;
    
    for (const doc of documents) {
      if (doc.status === "indexed" && doc.extractedText) {
        try {
          await this.indexDocument(doc.id, doc.extractedText, doc.metadata || undefined);
          indexed++;
        } catch (error) {
          console.error(`[RAG] Failed to re-index document ${doc.id}:`, error);
          failed++;
        }
      }
    }
    
    console.log(`[RAG] Re-indexing complete: ${indexed} indexed, ${failed} failed`);
  }

  /**
   * Delete document from knowledge base
   */
  async deleteDocument(documentId: number): Promise<void> {
    // Remove from vector store
    await vectorStore.removeDocument(documentId);
    
    // Delete embeddings from database
    await storage.deleteEmbeddingsByDocument(documentId);
    
    // Delete document
    await storage.deleteDocument(documentId);
    
    console.log(`[RAG] Deleted document ${documentId}`);
  }
}

// Singleton instance
export const ragService = new RAGService();
