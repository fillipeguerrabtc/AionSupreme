// server/curation/store.ts
// Store de curadoria com HITL (Human-in-the-Loop) - DB-backed
import { knowledgeIndexer } from "../rag/knowledge-indexer";
import { db } from "../db";
import { documents, curationQueue as curationQueueTable, CurationQueue, InsertDocument } from "@shared/schema";
import { sql, eq, and, desc } from "drizzle-orm";
import { curatorAgentDetector } from "./curator-agent";
import { DuplicateContentError } from "../errors/DuplicateContentError";

// Type alias for compatibility with existing code
export type CurationItem = CurationQueue;

// Custom error for auto-analysis timeout
export class AutoAnalysisTimeoutError extends Error {
  public readonly duration: number;
  
  constructor(message: string, duration: number) {
    super(message);
    this.name = 'AutoAnalysisTimeoutError';
    this.duration = duration;
    
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, AutoAnalysisTimeoutError);
    }
  }
}

// Timeout constant for auto-analysis (30s matches queue SLA)
const AUTO_ANALYSIS_TIMEOUT_MS = 30000;

/**
 * Wraps a promise with timeout protection using Promise.race pattern
 * Prevents LLM stalls from blocking ingestion pipeline
 */
async function withTimeout<T>(
  promise: Promise<T>,
  timeoutMs: number,
  operationName: string
): Promise<T> {
  let timeoutId: NodeJS.Timeout;
  const startTime = Date.now();
  
  const timeoutPromise = new Promise<T>((_, reject) => {
    timeoutId = setTimeout(() => {
      const duration = Date.now() - startTime;
      reject(new AutoAnalysisTimeoutError(
        `${operationName} exceeded timeout of ${timeoutMs}ms`,
        duration
      ));
    }, timeoutMs);
  });
  
  try {
    const result = await Promise.race([promise, timeoutPromise]);
    clearTimeout(timeoutId!);
    return result;
  } catch (error) {
    clearTimeout(timeoutId!);
    throw error;
  }
}

export const curationStore = {
  /**
   * Adiciona item √† fila de curadoria com an√°lise autom√°tica (se agente dispon√≠vel)
   */
  async addToCuration(
    data: {
      title: string;
      content: string;
      suggestedNamespaces: string[];
      tags?: string[];
      submittedBy?: string;
      contentHash?: string; // For deduplication
      normalizedContent?: string; // For fuzzy matching
      // Consolidated conversation fields (optional)
      conversationId?: number;
      messageTranscript?: Array<{
        role: "user" | "assistant" | "system";
        content: string;
        attachments?: Array<{
          type: "image" | "video" | "audio" | "document";
          url: string;
          filename: string;
          mimeType: string;
          size: number;
        }>;
        createdAt?: string;
      }>;
      attachments?: Array<{
        type: "image" | "video" | "audio" | "document";
        url: string;
        filename: string;
        mimeType: string;
        size: number;
      }>;
    }
  ): Promise<CurationItem> {
    // üß† GATE 1: PREPROCESSING PIPELINE (Compute BEFORE insert)
    // Following 2025 best practices for semantic deduplication
    console.log(`[Curation] üß† Gate 1: Preprocessing pipeline...`);
    
    // Import utilities
    const { generateContentHash, normalizeContent } = await import("../utils/deduplication");
    
    // Compute normalized content and hash (for exact duplicate detection)
    const normalizedText = normalizeContent(data.content);
    const contentHash = generateContentHash(data.content);
    
    console.log(`[Curation] ‚Üí Normalized: "${normalizedText.substring(0, 60)}..."`);
    console.log(`[Curation] ‚Üí Hash: ${contentHash.substring(0, 16)}...`);
    
    // Override data with computed values (ensure they're set!)
    data.contentHash = contentHash;
    data.normalizedContent = normalizedText;
    
    // üî• GATE 2: TIERED DUPLICATE DETECTION
    // Tier 1: Exact hash (instant)
    // Tier 2: Semantic similarity with pgvector (fast ANN)
    // Tier 3: LLM adjudication for borderline cases (0.85-0.92)
    // Returns embedding for persistence to avoid re-generation
    console.log(`[Curation] üî• Gate 2: Tiered duplicate detection...`);
    
    let generatedEmbedding: number[] | undefined = undefined;
    
    if (data.content) {
      const { deduplicationService } = await import("../services/deduplication-service");
      const duplicateCheck = await deduplicationService.checkCurationRealtimeDuplicate(
        data.content,
        contentHash,
        normalizedText
      );
      
      if (duplicateCheck) {
        // Capture embedding even if duplicate (for logging/analytics)
        generatedEmbedding = duplicateCheck.embedding;
        
        if (duplicateCheck.isDuplicate) {
          const location = duplicateCheck.isPending ? 'curation queue' : 'Knowledge Base';
          const errorMsg = duplicateCheck.isPending 
            ? `This content is already pending approval in the curation queue as "${duplicateCheck.documentTitle}". Skipped to avoid duplication.`
            : `This content already exists in the Knowledge Base as "${duplicateCheck.documentTitle}". Skipped to avoid duplication.`;
          
          // BUG #13 FIX: INFO n√£o ERROR (duplicate detection √© comportamento esperado!)
          console.log(`[Curation] ‚ÑπÔ∏è  Duplicate detected in ${location}: "${duplicateCheck.documentTitle}" - skipping to avoid duplication`);
          
          // Throw custom error with rich metadata for API consumers (type-safe class)
          throw new DuplicateContentError({
            duplicateOfId: duplicateCheck.documentId!,
            similarity: duplicateCheck.similarity ?? 1.0, // Se n√£o tem similarity, assume 1.0 (duplicado exato)
            newContentPercent: 0, // Duplicado = 0% conte√∫do novo
            reason: errorMsg
          });
        } else {
          // Not duplicate - capture embedding for persistence
          generatedEmbedding = duplicateCheck.embedding;
        }
      }
    }
    
    // üõ°Ô∏è FALLBACK: If dedup service didn't generate embedding, generate it now!
    // This ensures EVERY item has embedding for semantic search (critical!)
    if (!generatedEmbedding && data.content) {
      console.log(`[Curation] ‚ö†Ô∏è No embedding from dedup check - generating fallback embedding...`);
      try {
        const { embedText } = await import("../ai/embedder");
        const embeddingResult = await embedText(data.content);
        generatedEmbedding = embeddingResult; // embedText returns number[]
        console.log(`[Curation] ‚úÖ Fallback embedding generated (${generatedEmbedding.length} dimensions)`);
      } catch (embedError: any) {
        console.error(`[Curation] ‚ùå Failed to generate fallback embedding:`, embedError.message);
        // Continue without embedding - will be backfilled later
      }
    }
    
    console.log(`[Curation] ‚úÖ No duplicates found - proceeding with insert${generatedEmbedding ? ' (with embedding)' : ' (WITHOUT embedding - needs backfill)'}`);

    
    // STEP 1: Inserir na fila de curadoria (WITH embedding if generated)
    const [item] = await db.insert(curationQueueTable).values({
      title: data.title,
      content: data.content,
      suggestedNamespaces: data.suggestedNamespaces,
      tags: data.tags || [],
      status: "pending",
      submittedBy: data.submittedBy,
      contentHash: data.contentHash, // Store for O(1) dedup lookups
      normalizedContent: data.normalizedContent, // Store for fuzzy matching
      embedding: generatedEmbedding || null, // üéØ PERSIST embedding from dedup check (avoid re-generation!)
      // Consolidated conversation fields (if provided)
      conversationId: data.conversationId,
      messageTranscript: data.messageTranscript as any, // JSONB field
      attachments: data.attachments as any, // JSONB field
    }).returning();

    // STEP 1.5: Track query frequency for reuse-aware auto-approval (CRITICAL for reuse gate)
    // This enables cost-optimization by detecting frequently asked questions
    // üéØ CRITICAL: Track data.title (not content) to MATCH decide() queryText parameter
    // This ensures frequency lookups succeed when reuse gate checks frequency
    console.log(`[Curation] üìä ATTEMPTING query frequency tracking for title: "${data.title.substring(0, 50)}..."`);
    try {
      console.log(`[Curation] ‚Üí Importing queryFrequencyService...`);
      const { queryFrequencyService } = await import("../services/query-frequency-service");
      const primaryNamespace = data.suggestedNamespaces && data.suggestedNamespaces.length > 0 
        ? data.suggestedNamespaces[0] 
        : undefined;
      console.log(`[Curation] ‚Üí Calling track() with namespace="${primaryNamespace}", conversationId="${data.conversationId}"`);
      
      await queryFrequencyService.track(
        data.title,  // ‚úÖ MATCH with decide() queryText for reuse gate!
        primaryNamespace,
        data.conversationId?.toString()
      );
      console.log(`[Curation] ‚úÖ Query frequency tracking completed`);
    } catch (error: any) {
      // Non-critical - don't block curation if tracking fails
      console.error(`[Curation] ‚ùå Query frequency tracking failed:`, error.message, error.stack);
    }

    // STEP 2: Executar an√°lise autom√°tica IMEDIATAMENTE (garantir autoAnalysis existe)
    // CRITICAL: Auto-curator-processor depende de autoAnalysis para auto-approval
    // Se an√°lise falhar, item ficar√° pendente para HITL review (correto)
    try {
      console.log(`[Curation] ü§ñ Executando an√°lise autom√°tica SYNC para item ${item.id}...`);
      await this.runAutoAnalysis(item.id, data);
      console.log(`[Curation] ‚úÖ An√°lise autom√°tica completada para item ${item.id}`);
    } catch (error: any) {
      if (error instanceof AutoAnalysisTimeoutError) {
        console.error(`[Curation] ‚è±Ô∏è Item ${item.id}: Timeout ap√≥s ${error.duration}ms - aguardando HITL review`);
      } else {
        console.error(`[Curation] ‚ùå Erro na an√°lise autom√°tica do item ${item.id}:`, error.message);
      }
      console.error(`[Curation] ‚ö†Ô∏è Item ${item.id} criado SEM autoAnalysis - requer HITL review`);
      // Item foi criado mas sem an√°lise autom√°tica - vai precisar revis√£o humana (aceit√°vel)
    }

    return item;
  },

  /**
   * Executa an√°lise autom√°tica usando agente de curadoria (se dispon√≠vel)
   * Atualiza o campo 'note' com a recomenda√ß√£o do agente
   */
  async runAutoAnalysis(
    itemId: string,
    data: {
      title: string;
      content: string;
      suggestedNamespaces: string[];
      tags?: string[];
      submittedBy?: string;
    }
  ): Promise<void> {
    try {
      console.log(`[Curation] ü§ñ Iniciando an√°lise autom√°tica do item ${itemId}...`);

      // üî• FIX: Wrapper com fallback quando curatorAgentDetector falha
      let analysis;
      try {
        analysis = await withTimeout(
          curatorAgentDetector.analyzeCurationItem(
            data.title,
            data.content,
            data.suggestedNamespaces,
            data.tags || [],
            data.submittedBy
          ),
          AUTO_ANALYSIS_TIMEOUT_MS,
          'Auto-analysis LLM call'
        );
        
        // üî• FIX: Verificar se analysis √© null (quando curator agent offline)
        if (!analysis) {
          throw new Error('Curator agent returned null - agent may be offline');
        }
      } catch (curatorError: any) {
        console.warn(`[Curation] ‚ö†Ô∏è Curator agent falhou: ${curatorError.message} - tentando fallback LLM...`);
        
        // üî• FALLBACK: Usar generateWithFreeAPIs para an√°lise b√°sica
        const { generateWithFreeAPIs } = await import("../llm/free-apis");
        
        const fallbackPrompt = `Analise o seguinte conte√∫do para curadoria da base de conhecimento:

T√≠tulo: ${data.title}
Conte√∫do: ${data.content.substring(0, 1000)}...
Namespaces sugeridos: ${data.suggestedNamespaces.join(', ')}

Responda em JSON com:
{
  "score": <n√∫mero 0-100>,
  "recommended": <"approve"|"review"|"reject">,
  "reasoning": "<explica√ß√£o breve>",
  "concerns": [<lista de preocupa√ß√µes>]
}`;

        try {
          const fallbackResponse = await generateWithFreeAPIs({
            messages: [{ role: 'user', content: fallbackPrompt }],
            temperature: 0.3,
            maxTokens: 500
          });
          
          // Parse JSON response
          const jsonMatch = fallbackResponse.text.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            const parsed = JSON.parse(jsonMatch[0]);
            analysis = {
              score: parsed.score || 50,
              recommended: parsed.recommended || 'review',
              reasoning: parsed.reasoning || 'An√°lise autom√°tica via fallback LLM',
              concerns: parsed.concerns || [],
              flags: [],
              suggestedNamespaces: data.suggestedNamespaces
            };
            console.log(`[Curation] ‚úÖ Fallback LLM gerou an√°lise: score=${analysis.score}, rec=${analysis.recommended}`);
          } else {
            throw new Error('Fallback LLM n√£o retornou JSON v√°lido');
          }
        } catch (fallbackError: any) {
          console.error(`[Curation] ‚ùå Fallback LLM tamb√©m falhou: ${fallbackError.message}`);
          // üîí √öLTIMO RECURSO: An√°lise conservadora para HITL review
          analysis = {
            score: 50,
            recommended: 'review',
            reasoning: 'Ambos curator agent e fallback LLM falharam - requer revis√£o humana por seguran√ßa',
            concerns: ['An√°lise autom√°tica indispon√≠vel'],
            flags: ['manual-review-required'],
            suggestedNamespaces: data.suggestedNamespaces
          };
          console.log(`[Curation] üõ°Ô∏è Usando an√°lise conservadora - item vai para HITL review`);
        }
      }

      // Formatar nota com an√°lise autom√°tica
      const autoNote = `ü§ñ AN√ÅLISE AUTOM√ÅTICA (Agente de Curadoria):

üìä **Recomenda√ß√£o:** ${analysis.recommended === 'approve' ? '‚úÖ APROVAR' : analysis.recommended === 'reject' ? '‚ùå REJEITAR' : '‚ö†Ô∏è REVISAR MANUALMENTE'}
üéØ **Score de Qualidade:** ${analysis.score}/100

üìù **Racioc√≠nio:**
${analysis.reasoning}

${analysis.suggestedEdits ? `
‚úèÔ∏è **Sugest√µes de Edi√ß√£o:**
${analysis.suggestedEdits.title ? `- T√≠tulo: "${analysis.suggestedEdits.title}"\n` : ''}${analysis.suggestedEdits.tags ? `- Tags: ${analysis.suggestedEdits.tags.join(', ')}\n` : ''}
` : ''}${analysis.concerns && analysis.concerns.length > 0 ? `
‚ö†Ô∏è **Preocupa√ß√µes:**
${analysis.concerns.map((c: string) => `- ${c}`).join('\n')}
` : ''}
---
*An√°lise autom√°tica gerada pelo agente de curadoria. A decis√£o final √© humana.*`;

      // Atualizar item com an√°lise autom√°tica (SALVAR STRUCTURED DATA!)
      await db
        .update(curationQueueTable)
        .set({
          note: autoNote, // Human-readable markdown note
          autoAnalysis: { // STRUCTURED DATA for auto-approval
            score: analysis.score,
            flags: analysis.flags,
            suggestedNamespaces: analysis.suggestedNamespaces,
            reasoning: analysis.reasoning,
            recommended: analysis.recommended,
            concerns: analysis.concerns
          } as any,
          score: analysis.score, // Tamb√©m atualizar score legacy field
          updatedAt: new Date(),
        })
        .where(eq(curationQueueTable.id, itemId));

      console.log(`[Curation] ‚úÖ An√°lise autom√°tica conclu√≠da para item ${itemId}: ${analysis.recommended} (score: ${analysis.score})`);

      // üöÄ AUTO-APPROVAL SYSTEM (Configuration-driven via DB)
      // ======================================================================
      // Uses autoApprovalService to apply DB-configured thresholds and rules
      // Supports namespace filtering, content flags, and quality gates integration
      
      // üîí GUARD: S√≥ processa auto-approval se an√°lise foi bem-sucedida
      if (!analysis || typeof analysis.score !== 'number') {
        console.log(`[Curation] ‚ö†Ô∏è An√°lise autom√°tica incompleta - mantendo em HITL review por seguran√ßa`);
        return; // Sair sem processar - item fica pendente para revis√£o humana
      }
      
      // Import auto-approval service (dynamic import for service layer)
      const { autoApprovalService } = await import("../services/auto-approval-service");
      
      // Extract content flags and namespaces from structured analysis
      const contentFlags = analysis.flags || [];
      const namespaces = analysis.suggestedNamespaces || [];
      
      // Get auto-approval decision from service (uses DB config)
      // üéØ PHASE 1 FIX: Pass data.title as queryText to enable Greeting Gate + Reuse Gate
      // (Phase 2: Add dedicated originalQuery field for long-term accuracy)
      const decision = await autoApprovalService.decide(
        analysis.score,
        contentFlags,
        namespaces,
        undefined,  // qualityGatesPassed (not used yet)
        data.title  // queryText for greeting detection + frequency tracking
      );
      
      console.log(`[Curation] ü§ñ Auto-approval decision: ${decision.action.toUpperCase()}`);
      console.log(`[Curation] üìä Reason: ${decision.reason}`);
      console.log(`[Curation] ‚öôÔ∏è Config: minScore=${decision.configUsed.minApprovalScore}, maxScore=${decision.configUsed.maxRejectScore}, flags=${decision.configUsed.sensitiveFlags.join(',')}`);

      // Execute decision
      if (decision.action === 'approve' && analysis.recommended === 'approve') {
        console.log(`[Curation] üöÄ AUTO-APROVA√á√ÉO: ${decision.reason}`);
        console.log(`[Curation] üí° Conte√∫do seguro detectado - aprovando automaticamente para acelerar aprendizado`);
        
        try {
          // Auto-aprovar usando sistema autom√°tico
          const approvalResult = await this.approveAndPublish(itemId, 'auto-curator-agent');
          console.log(`[Curation] ‚úÖ Item ${itemId} auto-aprovado e publicado na KB (docId: ${approvalResult.publishedId})`);
          console.log(`[Curation] üöÄ Fluxo acelerado: KB ‚Üí Dataset ‚Üí Treino autom√°tico`);
          return; // Sair - item j√° processado
        } catch (autoApproveError: any) {
          console.error(`[Curation] ‚ùå Falha na auto-aprova√ß√£o:`, autoApproveError.message);
          console.error(`[Curation] Stack trace:`, autoApproveError.stack);
          console.log(`[Curation] ‚ö†Ô∏è Mantendo item ${itemId} em HITL review por seguran√ßa`);
          
          // Adicionar nota sobre falha de auto-approval
          try {
            const [currentItem] = await db.select().from(curationQueueTable).where(eq(curationQueueTable.id, itemId)).limit(1);
            await db.update(curationQueueTable)
              .set({
                note: (currentItem?.note || '') + `\n\n‚ö†Ô∏è Auto-aprova√ß√£o falhou: ${autoApproveError.message}\nItem requer revis√£o manual.`,
                updatedAt: new Date(),
              })
              .where(eq(curationQueueTable.id, itemId));
          } catch (noteError: any) {
            console.error(`[Curation] ‚ùå Erro ao adicionar nota de falha:`, noteError.message);
          }
          
          // Continua para HITL se auto-approval falhar
        }
      } else if (decision.action === 'reject' && analysis.recommended === 'reject') {
        console.log(`[Curation] ‚ùå AUTO-REJEI√á√ÉO: ${decision.reason}`);
        
        try {
          await this.reject(itemId, 'auto-curator-agent', `Automaticamente rejeitado. ${decision.reason}. ${analysis.reasoning}`);
          console.log(`[Curation] ‚úÖ Item ${itemId} auto-rejeitado`);
          return; // Sair - item j√° processado
        } catch (autoRejectError: any) {
          console.error(`[Curation] ‚ùå Falha na auto-rejei√ß√£o:`, autoRejectError.message);
          console.log(`[Curation] ‚ö†Ô∏è Mantendo em HITL review por seguran√ßa`);
        }
      } else {
        // HITL obrigat√≥rio (decision.action === 'review')
        console.log(`[Curation] ‚ö†Ô∏è HITL REVIEW NECESS√ÅRIO: ${decision.reason}`);
        console.log(`[Curation] üë§ Aguardando aprova√ß√£o humana para decis√£o final`);
      }

      // Se o agente recomendou edi√ß√µes, podemos aplic√°-las automaticamente (opcional)
      if (analysis.suggestedEdits && analysis.score >= 70) {
        console.log(`[Curation] üí° Agente sugeriu edi√ß√µes (score alto: ${analysis.score}), mas mantendo valores originais para revis√£o humana`);
      }
    } catch (error: any) {
      if (error instanceof AutoAnalysisTimeoutError) {
        console.error(`[Curation] ‚è±Ô∏è TIMEOUT: An√°lise autom√°tica excedeu ${error.duration}ms (limite: ${AUTO_ANALYSIS_TIMEOUT_MS}ms) para item ${itemId}`);
        console.warn(`[Curation] ‚ö†Ô∏è Item ${itemId} mantido em HITL review - LLM n√£o respondeu a tempo`);
      } else {
        console.error(`[Curation] ‚ùå Falha na an√°lise autom√°tica:`, error.message);
      }
      // N√£o propagar erro - an√°lise autom√°tica √© opcional, item fica pendente para HITL
    }
  },

  /**
   * Lista itens pendentes de curadoria
   */
  async listPending(): Promise<CurationItem[]> {
    return await db
      .select()
      .from(curationQueueTable)
      .where(eq(curationQueueTable.status, "pending"))
      .orderBy(desc(curationQueueTable.submittedAt));
  },

  /**
   * Lista todos os itens (com filtros opcionais)
   */
  async listAll(
    filters?: { status?: string; limit?: number }
  ): Promise<CurationItem[]> {
    const conditions = [];
    
    if (filters?.status) {
      conditions.push(eq(curationQueueTable.status, filters.status));
    }

    let items = await db
      .select()
      .from(curationQueueTable)
      .where(conditions.length > 0 ? and(...conditions) : undefined)
      .orderBy(desc(curationQueueTable.submittedAt));

    if (filters?.limit) {
      items = items.slice(0, filters.limit);
    }

    return items;
  },

  /**
   * Obt√©m item por ID
   */
  async getById(id: string): Promise<CurationItem | null> {
    const [item] = await db
      .select()
      .from(curationQueueTable)
      .where(eq(curationQueueTable.id, id))
      .limit(1);
    return item || null;
  },

  /**
   * Edita item pendente (t√≠tulo, conte√∫do, tags, namespaces, nota, attachments)
   */
  async editItem(
    id: string,
    updates: {
      title?: string;
      content?: string;
      tags?: string[];
      suggestedNamespaces?: string[];
      note?: string;
      attachments?: Array<{
        type: "image" | "video" | "audio" | "document";
        url: string;
        filename: string;
        mimeType: string;
        size: number;
        description?: string;
      }>;
    }
  ): Promise<CurationItem | null> {
    const item = await this.getById(id);
    if (!item || item.status !== "pending") return null;

    const [updated] = await db
      .update(curationQueueTable)
      .set({
        ...updates,
        updatedAt: new Date(),
      })
      .where(
        and(
          eq(curationQueueTable.id, id),
          eq(curationQueueTable.status, "pending")
        )
      )
      .returning();

    return updated || null;
  },

  /**
   * Aprova e publica item - integrado com Knowledge Base
   * üî• VERIFICA√á√ÉO UNIVERSAL DE DUPLICA√á√ÉO: 
   * - SEMPRE verifica KB completa antes de aprovar
   * - SEMPRE extrai e salva SOMENTE conte√∫do novo
   * - NUNCA duplica conte√∫do existente
   * 
   * @param id - Item ID
   * @param reviewedBy - Who approved (user or AUTO-CURATOR)
   * @param approvalNote - Optional audit note (e.g., REUSE-GATE reason)
   */
  async approveAndPublish(
    id: string,
    reviewedBy: string,
    approvalNote?: string
  ): Promise<{ item: CurationItem; publishedId: string }> {
    const item = await this.getById(id);
    if (!item || item.status !== "pending") {
      throw new Error("Item not found or already processed");
    }

    // üî• VERIFICA√á√ÉO UNIVERSAL DE DUPLICA√á√ÉO
    // SEMPRE verifica KB completa, independente de duplicationStatus
    let contentToSave = item.content;
    let isAbsorption = false;
    let duplicateDocId: number | null = null;

    try {
      // Se j√° tem duplicateOfId marcado, valida e usa direto
      if (item.duplicateOfId) {
        const numericId = Number(item.duplicateOfId);
        if (Number.isInteger(numericId) && numericId > 0) {
          duplicateDocId = numericId;
        } else {
          console.warn(`[Curation] ‚ö†Ô∏è duplicateOfId "${item.duplicateOfId}" is not a valid integer ID, forcing KB scan`);
          // Fall through to KB scan
        }
      }
      
      if (!duplicateDocId) {
        // Caso contr√°rio, FOR√áA scan completo da KB agora
        console.log(`[Curation] üîç Verificando duplica√ß√£o na KB para "${item.title}"...`);
        
        const { deduplicationService } = await import("../services/deduplication-service");
        const dupCheck = await deduplicationService.checkDuplicate({
          text: item.content,
          tenantId: 1,
          enableSemantic: true
        });

        if (dupCheck.isDuplicate && dupCheck.duplicateOf) {
          duplicateDocId = dupCheck.duplicateOf.id;
          console.log(`[Curation] ‚ö†Ô∏è Duplicata detectada: ${Math.round((dupCheck.duplicateOf.similarity || 0) * 100)}% similar a "${dupCheck.duplicateOf.title}" (ID: ${duplicateDocId})`);
        }
      }

      // Se encontrou duplicata, tenta absorver s√≥ o novo
      if (duplicateDocId) {
        const [originalDoc] = await db
          .select()
          .from(documents)
          .where(eq(documents.id, duplicateDocId))
          .limit(1);

        if (originalDoc) {
          const { analyzeAbsorption } = await import("../utils/absorption");
          const analysis = analyzeAbsorption(originalDoc.content, item.content);

          if (analysis.shouldAbsorb) {
            // ‚úÖ ABSORVER S√ì O NOVO
            contentToSave = analysis.extractedContent;
            isAbsorption = true;
            
            console.log(`[Curation] üî• AUTO-ABSOR√á√ÉO ativada para "${item.title}":
  Original: ${analysis.stats.originalLength} chars
  Extra√≠do: ${analysis.stats.extractedLength} chars
  Redu√ß√£o: ${analysis.stats.reductionPercent}%
  Novo: ${analysis.stats.newContentPercent}%
  Duplicado de: "${originalDoc.title}" (ID: ${originalDoc.id})`);
          } else {
            // Se n√£o vale absorver (<10% novo), rejeita automaticamente
            throw new DuplicateContentError({
              duplicateOfId: originalDoc.id,
              similarity: 1.0, // Default to 100% similarity (we know it's a duplicate)
              newContentPercent: analysis.stats.newContentPercent,
              reason: `${analysis.stats.newContentPercent}% new content (minimum 10% required). ${analysis.reason}`
            });
          }
        }
      } else {
        console.log(`[Curation] ‚úÖ Conte√∫do √∫nico detectado para "${item.title}", aprovando normalmente`);
      }
    } catch (verificationError: any) {
      // Se erro cr√≠tico na verifica√ß√£o, aborta aprova√ß√£o
      throw new Error(`Falha na verifica√ß√£o de duplica√ß√£o: ${verificationError.message}`);
    }

    // ü§ñ AUTO-CRIA√á√ÉO DE NAMESPACES E AGENTES (AUTONOMOUS CURATION)
    // ‚úÖ CR√çTICO: Fazer ANTES de criar documento para aplicar consolida√ß√£o everywhere
    let finalNamespaces = item.suggestedNamespaces || [];
    if (item.suggestedNamespaces && item.suggestedNamespaces.length > 0) {
      const { autoCreateNamespacesAndAgents } = await import("../services/auto-namespace-creator");
      const creationResult = await autoCreateNamespacesAndAgents(item.suggestedNamespaces, {
        source: "curation_approval",
        curationItemId: item.id,
        reviewedBy,
      });

      // ‚úÖ CR√çTICO: Aplicar mapeamento de consolida√ß√£o
      // Se houve consolida√ß√£o (>80% similar), usa namespace existente
      finalNamespaces = item.suggestedNamespaces.map(ns => 
        creationResult.consolidatedMapping[ns] || ns
      );

      // ‚úÖ CR√çTICO: Deduplica namespaces (se 2+ consolidaram para o mesmo)
      const uniqueNamespaces = new Set(finalNamespaces.filter(ns => ns && ns.trim()));
      finalNamespaces = Array.from(uniqueNamespaces);

      if (Object.keys(creationResult.consolidatedMapping).length > 0) {
        console.log(`[Curation] üîÑ Namespaces consolidados:`, creationResult.consolidatedMapping);
        console.log(`[Curation] üìù Namespaces finais deduplic+ ados:`, finalNamespaces);
      }
    }

    // ‚úÖ CR√çTICO: Garantir pelo menos 1 namespace v√°lido (fallback 'geral')
    if (!finalNamespaces || finalNamespaces.length === 0) {
      console.warn(`[Curation] ‚ö†Ô∏è No namespaces for item ${item.id}, using default 'geral'`);
      finalNamespaces = ['geral'];
    }

    // üî• NOVO: ZERO BYPASS - Salva imagens AP√ìS aprova√ß√£o (HITL completo)
    let finalAttachments = item.attachments;
    if (item.attachments && item.attachments.length > 0) {
      const { ImageProcessor } = await import("../learn/image-processor");
      const imageProcessor = await ImageProcessor.create();
      
      finalAttachments = await Promise.all(
        item.attachments.map(async (att: any) => {
          // Se tem base64 tempor√°rio, salva agora no filesystem
          if (att.base64 && att.type === "image") {
            console.log(`[Curation] üíæ Salvando imagem aprovada: ${att.filename}`);
            
            const buffer = Buffer.from(att.base64, 'base64');
            const localPath = await imageProcessor.saveImageFromBuffer(buffer, att.filename);
            
            // Retorna attachment com URL final (sem base64 tempor√°rio)
            return {
              type: att.type,
              url: localPath, // Path relativo final
              filename: att.filename,
              mimeType: att.mimeType,
              size: att.size,
              description: att.description
            };
          }
          // Se n√£o tem base64, retorna como est√°
          return att;
        })
      );
      
      console.log(`[Curation] ‚úÖ ${finalAttachments.filter((a: any) => a.type === 'image').length} imagens salvas ap√≥s aprova√ß√£o`);
    }

    // üî• PRODUCTION FIX: Use centralized preparation (prevents bypass)
    const { prepareDocumentForInsert } = await import("../utils/deduplication");
    
    // Prepare document data
    const documentData = prepareDocumentForInsert({
      title: item.title,
      content: contentToSave,
      contentHash: item.contentHash, // Will be generated if missing
      source: isAbsorption ? "curation_absorption" : "curation_approved",
      status: "approved",
      attachments: finalAttachments || undefined,
      metadata: {
        namespaces: finalNamespaces,
        tags: item.tags,
        curationId: item.id,
        reviewedBy,
        isAbsorption,
        ...(isAbsorption && item.duplicateOfId ? { absorbedFrom: item.duplicateOfId } : {})
      } as any,
    });
    
    // Create document record in database
    const [newDoc] = await db.insert(documents).values(documentData as any).returning();

    // Log attachments being saved
    if (item.attachments && item.attachments.length > 0) {
      console.log(`[Curation] üìé Salvando ${item.attachments.length} attachments junto com documento ${newDoc.id}`);
    }

    // üî• INDEXA√á√ÉO UNIFICADA: texto principal + descriptions dos attachments
    // Garante que imagens/v√≠deos sejam encontrados via busca textual
    let contentToIndex = newDoc.content;
    if (finalAttachments && finalAttachments.length > 0) {
      const attachmentDescriptions = finalAttachments
        .filter((att: any) => att.description && att.description.trim())
        .map((att: any) => `[${att.type === 'image' ? 'Imagem' : 'V√≠deo'}] ${att.description}`)
        .join('\n');
      
      if (attachmentDescriptions) {
        contentToIndex = `${newDoc.content}\n\n--- M√≠dia Anexada ---\n${attachmentDescriptions}`;
        console.log(`[Curation] üñºÔ∏è Indexando ${finalAttachments.length} attachments com descriptions na KB`);
      }
    }

    // üî• FIX CR√çTICO: Index approved content with NAMESPACE (singular, not namespaces plural!)
    // VectorStore.search expects 'namespace' (singular string), not 'namespaces' (array)
    const primaryNamespace = finalNamespaces && finalNamespaces.length > 0 
      ? finalNamespaces[0]  // Use first namespace
      : 'general';  // Fallback to default namespace
    
    await knowledgeIndexer.indexDocument(newDoc.id, contentToIndex, {
      namespace: primaryNamespace, // ‚Üê Singular string for VectorStore compatibility!
      title: item.title,
      tags: item.tags,
      source: "curation_approved",
      curationId: item.id,
    });

    // CRITICAL: Save to training_data_collection for auto-evolution
    // Only curated/approved content goes to training!
    try {
      const { trainingDataCollection } = await import("@shared/schema");
      
      
      // VALIDATION: Extract quality score from tags with fallback
      const qualityTag = item.tags.find(t => t.startsWith('quality-'));
      const qualityScore = qualityTag ? 
        Math.max(0, Math.min(100, parseInt(qualityTag.split('-')[1]) || 75)) : 
        75;
      
      if (!qualityTag) {
        console.warn(`[Curation] ‚ö†Ô∏è No quality tag for item ${item.id}, using default 75`);
      }
      
      // tenantId defaults to 1 in schema
      await db.insert(trainingDataCollection).values({
        conversationId: null, // Curated content doesn't have conversationId
        autoQualityScore: qualityScore,
        status: "approved", // Human-approved content is always approved
        formattedData: [{
          instruction: item.title,
          output: item.content,
        }],
        metadata: {
          source: "curation_approved",
          curationId: item.id,
          namespaces: finalNamespaces, // ‚úÖ USA NAMESPACES CONSOLIDADOS!
          tags: item.tags,
          reviewedBy,
        },
      } as any);
      
      console.log(`[Curation] ‚úÖ Saved to training_data_collection (quality: ${qualityScore}, namespaces: ${finalNamespaces.join(', ')})`);
    } catch (trainingError: any) {
      console.error(`[Curation] ‚ùå Failed to save training data:`, trainingError.message);
      // Fail closed: if training data save fails, throw error to prevent silent failures
      throw new Error(`Training data save failed: ${trainingError.message}`);
    }

    // Update curation queue item status in database
    const now = new Date();
    const [updatedItem] = await db
      .update(curationQueueTable)
      .set({
        status: "approved",
        reviewedBy,
        reviewedAt: now,
        statusChangedAt: now, // Track when status changed for 5-year retention
        publishedId: newDoc.id.toString(),
        note: approvalNote || null, // Optional audit note (e.g., REUSE-GATE reason)
        updatedAt: now,
      })
      .where(eq(curationQueueTable.id, id))
      .returning();

    console.log(`[Curation] ‚úÖ Approved and published item ${id} to KB as document ${newDoc.id}`);

    return { item: updatedItem, publishedId: newDoc.id.toString() };
  },

  /**
   * Publica item J√Å APROVADO para Knowledge Base
   * 
   * Diferente de approveAndPublish():
   * - Assume que item.status = 'approved' (n√£o muda status)
   * - Usado por approval-promotion-worker para backfill de items j√° aprovados
   * - Reutiliza l√≥gica completa de publica√ß√£o (deduplica√ß√£o, namespaces, indexa√ß√£o)
   * 
   * @param id - Item ID (must have status='approved')
   * @returns publishedId - ID do documento criado na KB
   */
  async publishApprovedItem(id: string): Promise<string> {
    const item = await this.getById(id);
    if (!item) {
      throw new Error("Item not found");
    }
    
    if (item.status !== "approved") {
      throw new Error(`Item ${id} must be approved before publishing (current status: ${item.status})`);
    }
    
    if (item.publishedId) {
      console.log(`[Curation] ‚ÑπÔ∏è Item ${id} already published as ${item.publishedId} - skipping`);
      return item.publishedId;
    }

    // üî• VERIFICA√á√ÉO UNIVERSAL DE DUPLICA√á√ÉO (same as approveAndPublish)
    let contentToSave = item.content;
    let isAbsorption = false;
    let duplicateDocId: number | null = null;

    try {
      if (item.duplicateOfId) {
        const numericId = Number(item.duplicateOfId);
        if (Number.isInteger(numericId) && numericId > 0) {
          duplicateDocId = numericId;
        } else {
          console.warn(`[Curation] ‚ö†Ô∏è duplicateOfId "${item.duplicateOfId}" is not a valid integer ID, forcing KB scan`);
          // Fall through to KB scan
        }
      }
      
      if (!duplicateDocId) {
        console.log(`[Curation] üîç Verificando duplica√ß√£o na KB para "${item.title}"...`);
        
        const { deduplicationService } = await import("../services/deduplication-service");
        const dupCheck = await deduplicationService.checkDuplicate({
          text: item.content,
          tenantId: 1,
          enableSemantic: true
        });

        if (dupCheck.isDuplicate && dupCheck.duplicateOf) {
          duplicateDocId = dupCheck.duplicateOf.id;
          console.log(`[Curation] ‚ö†Ô∏è Duplicata detectada: ${Math.round((dupCheck.duplicateOf.similarity || 0) * 100)}% similar a "${dupCheck.duplicateOf.title}" (ID: ${duplicateDocId})`);
        }
      }

      // Absor√ß√£o de conte√∫do (same logic)
      if (duplicateDocId) {
        const [originalDoc] = await db
          .select()
          .from(documents)
          .where(eq(documents.id, duplicateDocId))
          .limit(1);

        if (originalDoc) {
          const { analyzeAbsorption } = await import("../utils/absorption");
          const analysis = analyzeAbsorption(originalDoc.content, item.content);

          if (analysis.shouldAbsorb) {
            contentToSave = analysis.extractedContent;
            isAbsorption = true;
            console.log(`[Curation] üî• AUTO-ABSOR√á√ÉO: ${analysis.stats.reductionPercent}% redu√ß√£o`);
          } else {
            // üî• FIX: Retornar ID do documento existente ao inv√©s de throw
            // Isso permite que worker salve publishedId correto (prevent reprocessing)
            console.log(`[Curation] ‚ö†Ô∏è Conte√∫do duplicado (${analysis.stats.newContentPercent}% novo < 10%) - usando documento existente ${originalDoc.id}`);
            
            // Atualizar publishedId para apontar documento existente
            await db
              .update(curationQueueTable)
              .set({
                publishedId: originalDoc.id.toString(),
                note: item.note 
                  ? `${item.note}\n\n---\n‚ö†Ô∏è Duplicate content - linked to existing document ${originalDoc.id} (${analysis.stats.newContentPercent}% new content < 10% threshold).`
                  : `‚ö†Ô∏è Duplicate content - linked to existing document ${originalDoc.id} (${analysis.stats.newContentPercent}% new content < 10% threshold).`,
                updatedAt: new Date(),
              })
              .where(eq(curationQueueTable.id, id));
            
            // Retornar ID do documento existente (N√ÉO criar novo)
            return originalDoc.id.toString();
          }
        }
      } else {
        console.log(`[Curation] ‚úÖ Conte√∫do √∫nico detectado para "${item.title}"`);
      }
    } catch (verificationError: any) {
      throw new Error(`Falha na verifica√ß√£o de duplica√ß√£o: ${verificationError.message}`);
    }

    // Auto-cria√ß√£o de namespaces (same logic)
    let finalNamespaces = item.suggestedNamespaces || [];
    if (item.suggestedNamespaces && item.suggestedNamespaces.length > 0) {
      const { autoCreateNamespacesAndAgents } = await import("../services/auto-namespace-creator");
      const creationResult = await autoCreateNamespacesAndAgents(item.suggestedNamespaces, {
        source: "curation_approved_promotion",
        curationItemId: item.id,
        reviewedBy: item.reviewedBy || 'SYSTEM',
      });

      finalNamespaces = item.suggestedNamespaces.map(ns => 
        creationResult.consolidatedMapping[ns] || ns
      );

      const uniqueNamespaces = new Set(finalNamespaces.filter(ns => ns && ns.trim()));
      finalNamespaces = Array.from(uniqueNamespaces);
    }

    if (!finalNamespaces || finalNamespaces.length === 0) {
      finalNamespaces = ['geral'];
    }

    // Processamento de imagens (same logic)
    let finalAttachments = item.attachments;
    if (item.attachments && item.attachments.length > 0) {
      const { ImageProcessor } = await import("../learn/image-processor");
      const imageProcessor = await ImageProcessor.create();
      
      finalAttachments = await Promise.all(
        item.attachments.map(async (att: any) => {
          if (att.base64 && att.type === "image") {
            const buffer = Buffer.from(att.base64, 'base64');
            const localPath = await imageProcessor.saveImageFromBuffer(buffer, att.filename);
            return {
              type: att.type,
              url: localPath,
              filename: att.filename,
              mimeType: att.mimeType,
              size: att.size,
              description: att.description
            };
          }
          return att;
        })
      );
    }

    // Preparar documento (same logic)
    const { prepareDocumentForInsert } = await import("../utils/deduplication");
    const documentData = prepareDocumentForInsert({
      title: item.title,
      content: contentToSave,
      contentHash: item.contentHash,
      source: isAbsorption ? "curation_absorption" : "curation_approved",
      status: "approved",
      attachments: finalAttachments || undefined,
      metadata: {
        namespaces: finalNamespaces,
        tags: item.tags,
        curationId: item.id,
        reviewedBy: item.reviewedBy || 'SYSTEM',
        isAbsorption,
        ...(isAbsorption && item.duplicateOfId ? { absorbedFrom: item.duplicateOfId } : {})
      } as any,
    });
    
    // üî• DUPLICATE HANDLING: Check if duplicateDocId exists and is valid
    if (duplicateDocId) {
      // documents.id is INTEGER, so validate numeric ID before querying
      const numericId = Number(duplicateDocId);
      
      if (!Number.isInteger(numericId) || numericId <= 0) {
        console.warn(`[Curation] ‚ö†Ô∏è duplicateDocId "${duplicateDocId}" is not a valid integer ID, creating new document instead`);
        // Fall through to normal document creation
      } else {
        // Check if duplicate document exists
        const existingDocs = await db.select().from(documents)
          .where(eq(documents.id, numericId)).limit(1);
        
        if (existingDocs.length > 0) {
          const existingDoc = existingDocs[0];
          console.log(`[Curation] ‚ôªÔ∏è Reusing existing document ${numericId} (duplicate absorption)`);
          
          // Find the publishedId used when this document was first indexed
          // publishedId should be the stable identifier used by knowledgeIndexer
          const existingPublishedId = existingDoc.id.toString(); // Use doc.id as canonical publishedId
          
          // Update publishedId to point to existing document
          await db.update(curationQueueTable).set({
            publishedId: existingPublishedId,
            updatedAt: new Date(),
          }).where(eq(curationQueueTable.id, id));
          
          return existingPublishedId;
        } else{
          console.warn(`[Curation] ‚ö†Ô∏è duplicateDocId ${numericId} not found in documents table, creating new document`);
          // Fall through to normal document creation
        }
      }
    }
    
    // üî• TRANSACTION SAFETY: Try-catch with cleanup on failure
    let newDoc: typeof documents.$inferSelect;
    try {
      // Criar documento no DB
      [newDoc] = await db.insert(documents).values(documentData as any).returning();
    } catch (docError: any) {
      // If document creation fails (e.g., duplicate content_hash), throw immediately
      console.error(`[Curation] ‚ùå Failed to create document:`, docError.message);
      throw new Error(`Document creation failed: ${docError.message}`);
    }

    // Indexa√ß√£o com attachments
    let contentToIndex = newDoc.content;
    if (finalAttachments && finalAttachments.length > 0) {
      const attachmentDescriptions = finalAttachments
        .filter((att: any) => att.description && att.description.trim())
        .map((att: any) => `[${att.type === 'image' ? 'Imagem' : 'V√≠deo'}] ${att.description}`)
        .join('\n');
      
      if (attachmentDescriptions) {
        contentToIndex = `${newDoc.content}\n\n--- M√≠dia Anexada ---\n${attachmentDescriptions}`;
      }
    }

    const primaryNamespace = finalNamespaces[0] || 'general';
    
    // üî• TRANSACTION SAFETY: Cleanup orphan document if indexing fails
    try {
      await knowledgeIndexer.indexDocument(newDoc.id, contentToIndex, {
        namespace: primaryNamespace,
        title: item.title,
        tags: item.tags,
        source: "curation_approved",
        curationId: item.id,
      });
    } catch (indexError: any) {
      console.error(`[Curation] ‚ùå Indexing failed - cleaning up orphan document ${newDoc.id}:`, indexError.message);
      
      // Cleanup: Delete orphan document (no vector embeddings to clean - indexing failed before creation)
      await db.delete(documents).where(eq(documents.id, newDoc.id));
      
      throw new Error(`Indexing failed (orphan cleaned up): ${indexError.message}`);
    }

    // Salvar em training_data_collection with cleanup on failure
    try {
      const { trainingDataCollection } = await import("@shared/schema");
      const qualityTag = item.tags.find((t: any) => t.startsWith('quality-'));
      const qualityScore = qualityTag ? 
        Math.max(0, Math.min(100, parseInt(qualityTag.split('-')[1]) || 75)) : 
        75;
      
      await db.insert(trainingDataCollection).values({
        conversationId: null,
        autoQualityScore: qualityScore,
        status: "approved",
        formattedData: [{
          instruction: item.title,
          output: item.content,
        }],
        metadata: {
          source: "curation_approved_promotion",
          curationItemId: item.id,
          namespaces: finalNamespaces,
          tags: item.tags,
          reviewedBy: item.reviewedBy || 'SYSTEM',
        },
      } as any);
      
      console.log(`[Curation] ‚úÖ Saved to training_data_collection (quality: ${qualityScore})`);
    } catch (trainingError: any) {
      console.error(`[Curation] ‚ùå Training data save failed - cleaning up document ${newDoc.id}:`, trainingError.message);
      
      // üî• COMPLETE CLEANUP: Delete document + vector embeddings + training data
      try {
        // Delete vector embeddings first
        const { ragService } = await import("../rag/vector-store");
        await ragService.deleteDocument(newDoc.id);
        
        // Delete document from DB
        await db.delete(documents).where(eq(documents.id, newDoc.id));
        
        console.log(`[Curation] ‚úÖ Orphan cleaned up: document ${newDoc.id} + vector embeddings deleted`);
      } catch (cleanupError: any) {
        console.error(`[Curation] ‚ö†Ô∏è Cleanup failed for document ${newDoc.id}:`, cleanupError.message);
        // Don't throw - original error is more important
      }
      
      throw new Error(`Training data save failed (orphan cleaned up): ${trainingError.message}`);
    }

    // Atualizar publishedId (N√ÉO muda status - j√° √© approved!)
    await db
      .update(curationQueueTable)
      .set({
        publishedId: newDoc.id.toString(),
        updatedAt: new Date(),
      })
      .where(eq(curationQueueTable.id, id));

    console.log(`[Curation] ‚úÖ Published approved item ${id} to KB as document ${newDoc.id}`);

    return newDoc.id.toString();
  },

  /**
   * Rejeita item e agenda auto-dele√ß√£o em 30 dias (GDPR compliance)
   */
  async reject(
    id: string,
    reviewedBy: string,
    note?: string
  ): Promise<CurationItem | null> {
    const now = new Date();
    const expiresAt = new Date(now.getTime() + 30 * 24 * 60 * 60 * 1000); // 30 days from now
    
    const [updated] = await db
      .update(curationQueueTable)
      .set({
        status: "rejected",
        reviewedBy,
        reviewedAt: now,
        statusChangedAt: now,
        expiresAt, // Auto-delete after 30 days
        note: note || null,
        updatedAt: now,
      })
      .where(
        and(
          eq(curationQueueTable.id, id),
          eq(curationQueueTable.status, "pending")
        )
      )
      .returning();

    console.log(`[Curation] ‚è∞ Item ${id} rejeitado, auto-dele√ß√£o agendada para ${expiresAt.toISOString()}`);
    return updated || null;
  },

  /**
   * Lista hist√≥rico completo (aprovados + rejeitados) com reten√ß√£o de 5 anos
   * Filtra automaticamente itens com mais de 5 anos
   */
  async listHistory(
    filters?: { status?: "approved" | "rejected"; limit?: number }
  ): Promise<CurationItem[]> {
    const fiveYearsAgo = new Date();
    fiveYearsAgo.setFullYear(fiveYearsAgo.getFullYear() - 5);

    const conditions = [
      sql`${curationQueueTable.status} IN ('approved', 'rejected')`,
      sql`${curationQueueTable.statusChangedAt} >= ${fiveYearsAgo.toISOString()}`,
    ];

    if (filters?.status) {
      conditions.push(eq(curationQueueTable.status, filters.status));
    }

    let items = await db
      .select()
      .from(curationQueueTable)
      .where(and(...conditions))
      .orderBy(desc(curationQueueTable.statusChangedAt));

    if (filters?.limit) {
      items = items.slice(0, filters.limit);
    }

    return items;
  },

  /**
   * Remove item da fila (apenas para testes)
   */
  async remove(id: string): Promise<boolean> {
    const result = await db
      .delete(curationQueueTable)
      .where(eq(curationQueueTable.id, id))
      .returning();

    return result.length > 0;
  },
  
  /**
   * Limpa rejected items expirados (30 dias ap√≥s rejei√ß√£o)
   * Implementa GDPR data minimization e storage limitation
   * DEVE SER EXECUTADO DIARIAMENTE via cron job
   */
  async cleanupExpiredRejectedItems(): Promise<{ curationItemsDeleted: number } | null> {
    const now = new Date();

    const deletedItems = await db
      .delete(curationQueueTable)
      .where(
        and(
          eq(curationQueueTable.status, "rejected"),
          sql`${curationQueueTable.expiresAt} <= ${now}`
        )
      )
      .returning();

    if (deletedItems.length === 0) {
      console.log(`[Curation Cleanup] ‚úÖ Nenhum item rejeitado expirado para deletar`);
      return null;
    }

    console.log(`[Curation Cleanup] üóëÔ∏è ${deletedItems.length} itens rejeitados expirados deletados permanentemente`);
    return { curationItemsDeleted: deletedItems.length };
  },

  /**
   * 5-year retention cleanup for curation queue (approved/rejected items only)
   * Keeps pending items indefinitely until human decision
   * COMPLIANCE: LGPD Art. 16 (data minimization + legitimate retention period)
   */
  async cleanupOldCurationData(): Promise<{ curationItemsDeleted: number } | null> {
    const fiveYearsAgo = new Date();
    fiveYearsAgo.setFullYear(fiveYearsAgo.getFullYear() - 5);

    // Only delete finalized items (approved/rejected), keep pending indefinitely
    const deletedItems = await db
      .delete(curationQueueTable)
      .where(
        and(
          sql`${curationQueueTable.status} IN ('approved', 'rejected')`,
          sql`${curationQueueTable.statusChangedAt} <= ${fiveYearsAgo}`
        )
      )
      .returning();

    if (deletedItems.length === 0) {
      return null;
    }

    console.log(`[Curation Retention] Deleted ${deletedItems.length} curation items older than 5 years`);
    return { curationItemsDeleted: deletedItems.length };
  },
};
