/**
 * WEBSITE CRAWLER SERVICE - Servi√ßo de aprendizado de sites completos
 * 
 * Integra Deep Crawler com sistema de curadoria (HITL)
 */

import { DeepCrawler, type CrawledPage } from "./deep-crawler";
import { db } from "../db";
import { curationQueue } from "@shared/schema";

export interface CrawlRequest {
  url: string;
  tenantId: number;
  namespace?: string;
  maxDepth?: number;
  maxPages?: number;
}

export interface CrawlResult {
  totalPages: number;
  totalWords: number;
  totalImages: number;
  imagesWithDescriptions: number;
  curationItemsCreated: number;
  duration: number;
}

export class WebsiteCrawlerService {
  
  /**
   * Inicia crawling profundo de um site
   * Envia todo conte√∫do para curation queue (HITL)
   */
  async crawlWebsite(request: CrawlRequest): Promise<CrawlResult> {
    const startTime = Date.now();
    console.log(`[WebsiteCrawler] üöÄ Iniciando deep crawl: ${request.url}`);

    // Inicia crawler
    const crawler = new DeepCrawler(request.url, {
      maxDepth: request.maxDepth,
      maxPages: request.maxPages,
      includeImages: true,
      generateImageDescriptions: true
    });

    // Executa crawling
    const pages = await crawler.crawl();
    const stats = crawler.getStats();

    console.log(`[WebsiteCrawler] üìä Crawling conclu√≠do:`, stats);

    // Envia cada p√°gina para curation queue
    let curationItemsCreated = 0;

    for (const page of pages) {
      try {
        await this.sendToCurationQueue(page, request.tenantId, request.namespace);
        curationItemsCreated++;
      } catch (error: any) {
        console.error(`[WebsiteCrawler] ‚ùå Erro ao enviar p√°gina ${page.url} para curadoria:`, error.message);
      }
    }

    const duration = Date.now() - startTime;

    console.log(`[WebsiteCrawler] ‚úÖ Processo conclu√≠do em ${(duration / 1000).toFixed(1)}s`);
    console.log(`[WebsiteCrawler] üìù ${curationItemsCreated}/${pages.length} itens enviados para curadoria`);

    return {
      totalPages: stats.totalPages,
      totalWords: stats.totalWords,
      totalImages: stats.totalImages,
      imagesWithDescriptions: stats.imagesWithDescriptions,
      curationItemsCreated,
      duration
    };
  }

  /**
   * Envia p√°gina crawleada para curation queue
   */
  private async sendToCurationQueue(
    page: CrawledPage, 
    tenantId: number,
    namespace?: string
  ): Promise<void> {
    
    // Monta conte√∫do completo: texto + descri√ß√µes de imagens
    let fullContent = page.content;

    if (page.images.length > 0) {
      fullContent += '\n\n--- IMAGENS ENCONTRADAS ---\n';
      
      for (const img of page.images) {
        fullContent += `\n[Imagem: ${img.url}]\n`;
        if (img.description) {
          fullContent += `Descri√ß√£o: ${img.description}\n`;
        }
        if (img.alt) {
          fullContent += `Alt text: ${img.alt}\n`;
        }
      }
    }

    // Tags autom√°ticas
    const tags = [
      'url',
      'web-content',
      page.url,
      `quality-${this.calculateQualityScore(page)}`
    ];

    // Namespace sugerido
    const suggestedNamespaces = namespace ? [namespace] : ['kb/web'];

    // Insere na curation queue
    await db.insert(curationQueue).values({
      tenantId,
      title: page.title || 'Sem t√≠tulo',
      content: fullContent,
      suggestedNamespaces,
      tags,
      status: "pending",
      submittedBy: "website-crawler"
    } as any);

    console.log(`   ‚úì Enviado para curadoria: "${page.title}"`);
  }

  /**
   * Calcula score de qualidade baseado em m√©tricas da p√°gina
   */
  private calculateQualityScore(page: CrawledPage): number {
    const { wordCount, imageCount } = page.metadata;

    let score = 50; // Base

    // Mais palavras = melhor conte√∫do
    if (wordCount > 500) score += 20;
    else if (wordCount > 200) score += 10;

    // Imagens relevantes = conte√∫do rico
    if (imageCount > 5) score += 15;
    else if (imageCount > 2) score += 10;

    // T√≠tulo presente
    if (page.title && page.title !== 'Sem t√≠tulo') score += 5;

    return Math.min(100, score);
  }
}

export const websiteCrawlerService = new WebsiteCrawlerService();
